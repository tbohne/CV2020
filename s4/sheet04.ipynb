{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "463b91a1a9ea3c0e6ddcd202c9cebbb8",
     "grade": false,
     "grade_id": "cell-5bd18953238e78d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabrück University - Computer Vision (Winter Term 2020/21) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d12153e95200404858ea2a34740ac17",
     "grade": false,
     "grade_id": "cell-5b1c9d7364139283",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 04: Segmentation and Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "641d3cefe9b537abdced5c3e378c057f",
     "grade": false,
     "grade_id": "cell-7f36caad6a99f515",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, November 28, 2020**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b01bf6eee0d2ef1c25f7ad74999730d6",
     "grade": false,
     "grade_id": "math-exp",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (the exponential function) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy, does not give any points, and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebc6733562fac8716405aa3211f53e3e",
     "grade": false,
     "grade_id": "math-exp-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is an *exponential function*? How can it be characterized? What is special about $e^x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebfd1cecaa687ec46793840784814e92",
     "grade": true,
     "grade_id": "math-exp-a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9894dec6a8a57ffccf81cd11e2e269e0",
     "grade": false,
     "grade_id": "math-exp-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** How is the exponential function defined for complex arguments? In what way(s) does this generalize the real case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18e3b66094a4176e70210c80e349b42a",
     "grade": true,
     "grade_id": "math-exp-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fe2c7f6e8eafafff982bb18be856094",
     "grade": false,
     "grade_id": "math-exp-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** The complex exponential function allows to define a mapping $\\mathbb{R}\\to\\mathbb{C}$ by $x\\mapsto e^{ix}$? How does the graph of this mapping look like? Where are the points $e^{2\\pi i\\frac mn}$ for $m=0,...,n\\in\\mathbb{N}$ located on this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "975473d35b170f509697900ad803eee7",
     "grade": true,
     "grade_id": "math-exp-a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d674be6080ea518f9020470574062da",
     "grade": true,
     "grade_id": "math-exp-a3b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "677ff98e8538b08cffb92b0d9e274499",
     "grade": false,
     "grade_id": "seg-hist",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Histogram-based segmentation [5 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8567e20aed414f16cb0b807d0ed3a79f",
     "grade": false,
     "grade_id": "seg-hist-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Histogram-based segmentation\n",
    "\n",
    "What is histogram-based segmentation? What are it's goals, benefits, and problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "387c7bb95dc38674458347c09db77d14",
     "grade": true,
     "grade_id": "seg-hist-a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "A histogram is computed from the pixels of the image, and the extrema in the histogram are used to locate the clusters in the image.  \n",
    "\n",
    "**Goals**:\n",
    "- separate foreground and background\n",
    "- background as a single segment\n",
    "- one segment for each other entity\n",
    "\n",
    "**Benefits**:  \n",
    "- histogram-based methods are very efficient compared to other image segmentation methods because they typically require only one pass through the pixels\n",
    "\n",
    "**Problems**:  \n",
    "- it may be difficult to identify significant extrema in the image\n",
    "- hard to find suitable threshold for segmentation\n",
    "- non-uniform brightness of background - homogeneous background would simplify the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b1c34e5e78db8919509851a8fed0e7d",
     "grade": false,
     "grade_id": "seg-hist-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Threshold computation\n",
    "\n",
    "There exist different methods to automatically determine a threshold for an image. Find at least two that are provided by scikit-image and describe them in more detail. Then apply them to the images `schrift.png` and `pebbles.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcbbb249da1fa2f5206ac675cdd17fcf",
     "grade": true,
     "grade_id": "seg-hist-a2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Thresholding is used to create a binary image from a grayscale image.  \n",
    "\n",
    "Scikit-image includes the function `try_all_threshold` to evaluate thresholding algorithms provided by the library.  \n",
    "The results of applying all the thresholding functions is depicted below. Two of the used functions are:  \n",
    "\n",
    "- **Otsu’s method** (`threshold_otsu`)\n",
    "    - calculates an optimal threshold by maximizing the variance between two classes of pixels, which are separated by the threshold (minimizes the intra-class variance)\n",
    "- **Mean** (`threshold_mean`)\n",
    "    - returns a threshold value based on the mean of grayscale values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eac1946115c2a133905fcba7cf2eb97",
     "grade": false,
     "grade_id": "seg-hist-code",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get an impression of how the histograms look\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "\n",
    "img1 = imread('images/schrift.png')\n",
    "img2 = imread('images/pebbles.jpg') \n",
    "\n",
    "plt.figure(figsize=(15, 10)) \n",
    "plt.gray()\n",
    "plt.subplot(2,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img1)\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(img1.flatten(), 256, (0, 255))\n",
    "plt.subplot(2,2,3)\n",
    "plt.axis('off')\n",
    "plt.imshow(img2)\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(img2.flatten(), 256, (0, 255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ac3f174d5e41cc841657cc9ddbca13e",
     "grade": true,
     "grade_id": "cell-a030c58775d405f5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "# YOUR CODE HERE\n",
    "img1 = imread('images/pebbles.jpg')\n",
    "img2 = imread('images/schrift.png')\n",
    "# https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html\n",
    "fig, ax = try_all_threshold(img1, figsize=(10, 8), verbose=False)\n",
    "plt.show()\n",
    "fig, ax = try_all_threshold(img2, figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fde035d26d5778638c5753c9efcbbd6",
     "grade": false,
     "grade_id": "seg-hist-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Shading\n",
    "\n",
    "Shading may cause a problem to histogram based segmentation. In the lecture (CV-07 slide 13), it was proposed to compute a shading image to deal with that problem. Apply this approach to the images `schrift.png` and `pebbles.jpg`. You may use filter functions from scikit-image for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21eadba369183ea780e5be21b62fb577",
     "grade": true,
     "grade_id": "seg-hist-a3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "\n",
    "img1 = imread('images/schrift.png').astype(float) / 255\n",
    "img2 = imread('images/pebbles.jpg').astype(float) / 255\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# threshold img without shading img\n",
    "thresh_img1 = img1 > threshold_otsu(img1)\n",
    "thresh_img2 = img2 > threshold_otsu(img2)\n",
    "\n",
    "# threshold img with shading img\n",
    "\n",
    "# if the image consists mainly of foreground and background, \n",
    "# the shading image can be obtained using a ranking filter (return local maximum of an image)\n",
    "# --> window must be large enough to always contain at least 1 fg and 1 bg pixel\n",
    "shading_img1 = rank.maximum(img1, np.ones((7, 7)))\n",
    "# it's not working that well for the pebbles, because fg and bg are not that easily separable\n",
    "shading_img2 = rank.maximum(img2, np.ones((25, 25)))\n",
    "\n",
    "# divide img by background img\n",
    "corr_img1 = img1 / shading_img1\n",
    "# normalize\n",
    "corr_img1 *= (255 / corr_img1.max())\n",
    "new_thresh1 = corr_img1 > threshold_otsu(corr_img1)\n",
    "\n",
    "# divide img by background img\n",
    "corr_img2 = img2 / shading_img2\n",
    "# normalize\n",
    "corr_img2 *= (255 / corr_img2.max())\n",
    "new_thresh2 = corr_img2 > threshold_otsu(corr_img2)\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.title('original text')\n",
    "plt.imshow(img1, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.title('thresholding with original text')\n",
    "plt.imshow(thresh_img1, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.title('shading image')\n",
    "plt.imshow(shading_img1, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.title('shading image + thresholding text')\n",
    "plt.imshow(new_thresh1, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.title('original pebbles')\n",
    "plt.imshow(img2, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.title('thresholding with original pebbles')\n",
    "plt.imshow(thresh_img2, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.title('shading image')\n",
    "plt.imshow(shading_img2, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.title('shading image + thresholding pebbles')\n",
    "plt.imshow(new_thresh2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16c4b2971fb8b064046735817ef231ed",
     "grade": false,
     "grade_id": "pyramid",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Pyramid representation [5 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99c26c3401f3962484e586624762891e",
     "grade": false,
     "grade_id": "pyramid-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is the *Gaussian pyramid*? How does the **reduce** operation work? Explain in your own words what low pass filtering is and why it should be used when building the pyramid? Implement the **reduce** operation and generate a figure similar to the one on (CV-07 slide 32)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f173f8302a5dc5bf15734d3be710d60",
     "grade": true,
     "grade_id": "pyramid-a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "A pyramid representation is a type of multi-scale representation in which an image is subject to repeated smoothing and subsampling.  \n",
    "In a Gaussian pyramid, subsequent images are weighted down using a Gaussian blur and scaled down. Each pixel containing a local average corresponds to a neighborhood pixel on a lower level of the pyramid. This technique is used especially in texture synthesis.  \n",
    "Pyramids are used as multi-scale representation for computing multi-scale image features from real-world image data in a very efficient manner.\n",
    "\n",
    "**Reduce Operation**:\n",
    "Each pixel of level $i+1$ replaces four pixels of level $i$ (not necessarily calculated from these four).  \n",
    "\n",
    "**Low Pass Filtering**:\n",
    "Low pass filtering removes high frequencies to avoid artifacts which arise due to a violation of the sampling theorem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e77bc727df2ad223946294c65154cd4",
     "grade": true,
     "grade_id": "pyramid-impl1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "\n",
    "img = imread('images/mermaid.png').astype(float) / 255\n",
    "reduced_img = img.copy()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "kernel = 1 / 16 * np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "def reduce(img):\n",
    "    # only use every 2nd row and col (reduction)\n",
    "    # gaussian filtering + sub-sampling\n",
    "    filtered = ndimage.convolve(img, kernel)[::2, ::2]\n",
    "    # return normalized version\n",
    "    return filtered * 1.0 / filtered.max()\n",
    "\n",
    "while img.size > 2:\n",
    "    img = reduce(img)\n",
    "    reduced_img[-img.shape[0]:, :img.shape[1]] = img\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.gray()\n",
    "plt.imshow(reduced_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9a037fa7aad112ac3128722aa44cd3c",
     "grade": false,
     "grade_id": "pyramid-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is the **expand** operation? Why can the **reduce** operation not be inverted? Implement the **expand** operation and generate an image similar to the one on (CV-07 slide 34)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03e49c6c116a7920df087b3c4c77a986",
     "grade": true,
     "grade_id": "pyramid-a2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The expand operation reproduces level $i$ from level $i+1$. The pixels of level $i$ are generated by interpolation of pixels of levle $i+1$.  \n",
    "It yields a blurred image, because the reduce operation can not be inverted since we don't know the values of the 'lost' pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c8fc36ef4b248c154425a0ce288e37b",
     "grade": true,
     "grade_id": "pyramid-impl2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "\n",
    "img = imread('images/mermaid.png').astype(float) / 255\n",
    "steps = 4\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def expand(img):\n",
    "    pyr = np.zeros((img.shape[0] * 2, img.shape[1] * 2))\n",
    "    pyr[::2, ::2] = img\n",
    "    # TODO: not sure about 'kernel * steps' - otherwise too dark\n",
    "    return ndimage.convolve(pyr, kernel * steps, mode='constant')\n",
    "\n",
    "for _ in range(steps):\n",
    "    img = reduce(img)\n",
    "pyramid_image = np.zeros((img.shape[0] * (2 ** steps), img.shape[1] * (2 ** steps)))\n",
    "\n",
    "res = []\n",
    "for _ in range(steps):    \n",
    "    img = expand(img)\n",
    "    res.append(img)\n",
    "\n",
    "for img in res[::-1]:\n",
    "    pyramid_image[-img.shape[0]:, :img.shape[1]] = img\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.gray()\n",
    "plt.imshow(pyramid_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ec4e7a1bcda0fcaf0c78b2fad24bff0",
     "grade": false,
     "grade_id": "texture",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: Texture Segmentation [5 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39e355ad0681884ec136db8900e453e7",
     "grade": false,
     "grade_id": "texture-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is texture? Try to define it in your own words. Can there be a standard definition? What problems do you expect for texture based segmentation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22b8fab58ba00ce396b0cf303d49315c",
     "grade": true,
     "grade_id": "texture-a1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "**Texture** can be seen as the structure or patterning of a surface, but has no precise definition.  \n",
    "It's an important feature for segmentation, because it can be used as a homogeneity condition.  \n",
    "In general, texture is when there are groups of pixels exhibiting common properties and can not be defined for single pixels.  \n",
    "As there is no hard definition, texture and texture measures are always a matter of definition.\n",
    "\n",
    "Besides the lack of a hard definition, texture interpretation often highly depends on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed8a91148463ce90d8c1d66663ed0a6",
     "grade": false,
     "grade_id": "texture-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is a co-occurrence matrix? How can it be used to characterize texture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36c32b03d2223058107b9826893aa6dd",
     "grade": true,
     "grade_id": "texture-a2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "It's an important tool to recognize texture. It's basically a 2D histogram based on pairs of pixels representing the correlation between the pixels.  \n",
    "\n",
    "To characterize texture, one has to evaluate the co-occurrence matrix by different texture features, e.g. the Haralick features:\n",
    "- contrast\n",
    "- entropy\n",
    "- homogeneity\n",
    "- energy\n",
    "- .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d081a6b5eef2a4cfc571feb637e6cebf",
     "grade": false,
     "grade_id": "texture-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "**c)** Implement a function to compute the co-occurence matrix of an image (patch). Apply it and compare your results to (CV-07 slide 54)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "513c2aa1f59394de5bee2940d1c19001",
     "grade": true,
     "grade_id": "texture-a3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio \n",
    "\n",
    "img = imageio.imread('images/mermaid.png')#, mode='L')\n",
    "\n",
    "def get_patch(img, x, y, size=40):\n",
    "    \"\"\"\n",
    "    Extract a rectangular patch from an image and mark it in the original image.\n",
    "    \n",
    "    Args:\n",
    "        img (nndarray): Input image.\n",
    "        x (uint): X-coordinate.\n",
    "        y (uint): Y-coordinate.\n",
    "        size (uint): Size of the patch.\n",
    "        \n",
    "    Returns:\n",
    "        result: The extracted patch.\n",
    "    \"\"\"\n",
    "    result = img[x:x+size,y:y+size].copy()\n",
    "    img[x:x+size, [y,y+1,y+size,y+size+1]] = 0\n",
    "    img[[x,x+1,x+size,x+size+1], y:y+size] = 0\n",
    "    return result\n",
    "\n",
    "patches = []\n",
    "patches.append(get_patch(img, 50,130))\n",
    "patches.append(get_patch(img, 110,80))\n",
    "patches.append(get_patch(img, 260,340))\n",
    "patches.append(get_patch(img, 310,110))\n",
    "patches.append(get_patch(img, 100,440))\n",
    "\n",
    "def cooccurrence(img, dx=1, dy=1):\n",
    "    \"\"\"\n",
    "    Compute a co-occurence matrix for the given image.\n",
    "    \n",
    "    Args:\n",
    "        img          the grayscale image (uint8)\n",
    "        dx,dy        the offset between the two reference points\n",
    "\n",
    "    Returns:\n",
    "        matrix       the co-occurence matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    matrix = np.zeros((256, 256))\n",
    "    # dx 1 --> 0; dy 1 --> 90\n",
    "    alpha = 0 if dx == 1 else 90\n",
    "    d = np.array([int(np.cos(np.deg2rad(alpha))), int(np.sin(np.deg2rad(alpha)))])\n",
    "\n",
    "    # iteration over 4 loops is way too slow, but we don't have to do it since we\n",
    "    # already have all the gray value combinations in the matrix\n",
    "    # --> basically counting the combinations (number of co-occurrences)\n",
    "    for x in range((img.shape[0] - d[0])):\n",
    "        for y in range((img.shape[1] - d[1])):\n",
    "            p = img[x][y]\n",
    "            p_plus_d = img[x + d[0]][y + d[1]]\n",
    "            # count co-occurrence\n",
    "            matrix[p][p_plus_d] += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.gray()\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "i = 0\n",
    "for p in patches:\n",
    "    plt.subplot(len(patches), 3, i + 1); plt.axis('off'); plt.imshow(p)\n",
    "    # For visualization one may apply some extra me, e.g., logarithmization or binarization\n",
    "    plt.subplot(len(patches), 3, i + 2); plt.imshow(np.log(1 + cooccurrence(p, 0, 1)), interpolation='none')\n",
    "    plt.subplot(len(patches), 3, i + 3); plt.imshow(cooccurrence(p, 1, 0) > 0, interpolation='none')\n",
    "    i += 3\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c523f27c15187a60c9394379d18f2e9",
     "grade": false,
     "grade_id": "region-merging",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 4: Region merging [5 Points]\n",
    "\n",
    "Implement the *region merging* algorithm (CV-07 slide 39) and apply it to the image `segments.png` (or some part of it). Use a simple *homogeneity condition*, e.g. that the maximal difference between gray values in a segment is not larger than a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2872824c86c7569d17591959a63d0f25",
     "grade": true,
     "grade_id": "region-merging-impl",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "img = imageio.imread('./images/segments.png', pilmode='L')\n",
    "\n",
    "# Choosing a large image region lengthens computation time\n",
    "img = img[64:128,64:128]\n",
    "\n",
    "# compute the `label` array by implementing \"region merging\"\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#############################################\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.gray()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(label, cmap='prism')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfc57266945a58118a1744ac7bfebce8",
     "grade": false,
     "grade_id": "cell-d4ff17dad755ebc5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Bonus: Painting with a webcam using color detection [0 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43b71587744e8f85bd2a8987ed199a33",
     "grade": false,
     "grade_id": "cell-f266723bef52f124",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your webcam: Images\n",
    "From now on we will try to make the exercises a bit more interactive and use live feed from your webcam. Unfortunately, using the webcam may not always work out of box (depending on your hardware/os configuration). So first make sure that you can grab an image from the webcam.\n",
    "\n",
    "1. Use the `imageio` library as presented in the tutorial sessions. You will probably need to install `ffmpeg` packages as shown in the tutorial code.\n",
    "1. Use the `cv2` library (opencv will use `gstreamer`). You will probably need to install then `opencv` package.\n",
    "\n",
    "Hint: Sometimes it helps to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set this flag to either use \"imageio\" or \"cv2\"\n",
    "use_imageio = True\n",
    "if use_imageio:\n",
    "    # use imageio for accessing the webcam (requires ffmpeg to be installed on your computer)\n",
    "    import imageio\n",
    "    try:\n",
    "        reader = imageio.get_reader('<video0>')\n",
    "        img = reader.get_next_data()\n",
    "        ok = True\n",
    "        reader.close()\n",
    "    except:\n",
    "        ok = False\n",
    "else:\n",
    "    # use opencv for accessing the webcam\n",
    "    import cv2\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    ok, img = camera.read()\n",
    "    camera.release()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "if ok:\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Accessing your webcam failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a39dc94c54a254e56cfb9d76685089b6",
     "grade": false,
     "grade_id": "cell-ae7cd6d7b3fc1ee6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your webcam: Video\n",
    "You can now test your webcam with video. You can either select the methods presented in the tutorial session, namely `imageio` and `visvis`, or use `cvloop`. We recommend using the first method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c707c979540a9a5326900fe900ad92f0",
     "grade": false,
     "grade_id": "cell-8eed8027ad20ff2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**imageio and visvis**\n",
    "\n",
    "\n",
    "To test these modules run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import visvis as vv\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "reader = imageio.get_reader('<video0>')\n",
    "\n",
    "img = reader.get_next_data()\n",
    "res = np.zeros_like(img)\n",
    "\n",
    "fig = vv.figure() \n",
    "a1 = vv.subplot(121)\n",
    "im_v = vv.imshow(img, clim=(0, 255))\n",
    "a1 = vv.subplot(122)\n",
    "res_v = vv.imshow(res, clim=(0, 255))\n",
    "\n",
    "for im in reader:\n",
    "    vv.processEvents()     \n",
    "    im_v.SetData(im)\n",
    "    res_v.SetData(255 - im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "045844818e14a0ec6fa10885aa966c05",
     "grade": false,
     "grade_id": "cell-60ffb2d0d6a66bc6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**cvloop**\n",
    "\n",
    "Atlernatively you can use `cvloop`. To install `cvloop` first activate your cv environment and then run the follwing cell. We recommend using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71a1160cf1678ed58225d706991d1972",
     "grade": false,
     "grade_id": "cell-60ffb2d0d6a66bc62",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install cvloop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd3b584e77ece05ec5fc78d2df6a09c2",
     "grade": false,
     "grade_id": "cell-60ffb2d0d6a66bc63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Check that it works by executing the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05d34599f82b8c8609369b2195d76a48",
     "grade": false,
     "grade_id": "cell-af8e63521a144695",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from cvloop import cvloop\n",
    "cvl = cvloop(function=lambda frame: 255 - frame, side_by_side=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87610938e96904d34b15e0832c65f84f",
     "grade": false,
     "grade_id": "cell-5eb388ec5f5c3f3f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a)\n",
    "In this task we will track a small colored object (like the cap of a pen) in front of a neutral background of a different color. We will use the location of the object to paint on a virtual canvas. For that you have to implement the following tasks in the `draw_func` function:\n",
    "\n",
    "* Convert the image `img` given to the `draw_func` into HSV color space. \n",
    "* Measure the color of your object. You may return the converted image and interactively measure the color with your mouse. Define your measured hue value in a constant\n",
    "* Discard all channel except the hue channel. \n",
    "* Find the location with the most similar hue to the measured hue of your object.\n",
    "* Paint a marker, for example a circle, at this position in `img_draw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9419615f542c900430b6f5ea2dd2fb6",
     "grade": true,
     "grade_id": "cell-ba6ce24dc320a7341",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import imageio\n",
    "import visvis as vv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.draw import disk\n",
    "\n",
    "# Adapt this hue value to the hue of your object\n",
    "hue = .4\n",
    "\n",
    "# A global canvas to draw on\n",
    "canvas = np.zeros((480,640,3), np.uint8) \n",
    "\n",
    "# radius and color of the brush\n",
    "radius = 5\n",
    "color = (255,255,255)\n",
    "\n",
    "# saturation threshold for object\n",
    "thresh = .2\n",
    "\n",
    "def draw_func(img):\n",
    "    \"\"\"\n",
    "    Draw a circle on img_draw at the detected object location.\n",
    "    \n",
    "    Args:\n",
    "        img          the RGB input image (uint8)\n",
    "\n",
    "    Returns:\n",
    "        img_draw     img with circle drawn at postion of object\n",
    "    \"\"\"\n",
    "    global canvas, hue, radius, color\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    return canvas\n",
    "\n",
    "\n",
    "\n",
    "# Make a figure and axes with dimensions as desired.\n",
    "fig = plt.figure(figsize=(8, 1))\n",
    "ax = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "cb = mpl.colorbar.ColorbarBase(ax, cmap=mpl.cm.hsv, orientation='horizontal',\n",
    "                               norm=mpl.colors.Normalize(vmin=0, vmax=1))\n",
    "cb.set_ticks([hue])\n",
    "cb.set_label('the hue value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test your function with single image. You may either grab an image from your webcam (as described above),\n",
    "# or choose an arbitrary image from wherever you like\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "draw_func(img)\n",
    "plt.subplot(1,2,1); plt.imshow(img)\n",
    "plt.subplot(1,2,2); plt.imshow(canvas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run your function with imageio and visvis or alternatively with cvloop\n",
    "\n",
    "import imageio\n",
    "import visvis as vv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "reader = imageio.get_reader('<video0>')\n",
    "\n",
    "img = reader.get_next_data()\n",
    "res = np.zeros_like(img)\n",
    "\n",
    "fig = vv.figure() \n",
    "a1 = vv.subplot(121)\n",
    "im_v = vv.imshow(img, clim=(0, 255))\n",
    "a1 = vv.subplot(122)\n",
    "res_v = vv.imshow(res, clim=(0, 255))\n",
    "\n",
    "for im in reader:\n",
    "    # mirror the image to make drawing easier\n",
    "    im = im[:,::-1,:]\n",
    "    vv.processEvents()     \n",
    "    im_v.SetData(im)\n",
    "    res_v.SetData(draw_func(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6a8311b6275a347f1db08d84aefbaf",
     "grade": false,
     "grade_id": "cell-ba6ce24dc320a734",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "from cvloop import cvloop\n",
    "\n",
    "# Now use cvloop to run the algorithm live on webcam data     \n",
    "cvl = cvloop(function=draw_func, side_by_side=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('cv': conda)",
   "language": "python",
   "name": "python38664bitcvcondace24c6b5e63f40158ccc45b6baeafab5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "700px",
    "left": "0px",
    "right": "1194px",
    "top": "135px",
    "width": "150px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}