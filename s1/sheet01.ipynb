{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71319db685bffbe066b3c06ee591e857",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabrück University - Computer Vision (Winter Term 2020/21) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee0685d745192358300cd25c4efc45a5",
     "grade": false,
     "grade_id": "h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 01: Basic Operations - Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a11905104e1792fcf74c74d76b566e",
     "grade": false,
     "grade_id": "h02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This is the first \"real\" homework sheet.\n",
    "\n",
    "The homework sheets will usually be available on Saturday and are supposed to be solved in groups of three. They have to be handed in before Sunday morning of the following week. The exercises are then presented to your tutor in a small feedback session. To acquire the admission for the final exam, you will have to pass 𝑁−2 of the weekly provided exercise sheets.\n",
    "\n",
    "Sign up for a group on Stud.IP (See Participants -> Functions/Groups). The times mentioned there are the times for the feedback session of your group. If none of them fits, send any of the tutors an e-mail so we can try to arrange something.\n",
    "\n",
    "Your group will have a group folder in Stud.IP under Documents. Upload your solutions there to hand them in.\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, November 07, 2020**. Please upload your results to your group's Stud.IP folder. In case you cannot do this first sheet (due to technical or organizational problems) please upload a description of your problem instead. Your tutor will help you to solve the problems in the first feedback session and you may hand in this sheet together with the second sheet one week later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "963490a52ec335486114f07426d80789",
     "grade": false,
     "grade_id": "conv-theory",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Twodimensional Convolution [8 Points]\n",
    "\n",
    "This exercise is purely theoretical and does not require implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "beb7b42e40bc3fe467f855f91c260b1a",
     "grade": false,
     "grade_id": "conv-theory-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Definition\n",
    "\n",
    "Describe in your own words how convolution works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc7db21fd0a445c1915f630c5cf3d48b",
     "grade": true,
     "grade_id": "conv-theory-a1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "- in general, a convolution is an operation that combines two functions to get a new one\n",
    "- in an image processing context, it's an operation that takes in two different grids of values and combines them to get a new grid of values\n",
    "- typically, one of the two grids is smaller and called kernel\n",
    "- the result of applying the kernel (smaller matrix) to the image (bigger matrix) would be another image and we'd say that we convolved the original image using the kernel\n",
    "- so, a convolution in the image processing context is defined by a filter kernel (mask, receptive field) which is just a matrix\n",
    "- we basically replace each pixel value of an image by a new value that is based on a functional evaluation of its neighboring pixels\n",
    "- linear kernels are the easiest (and most efficient)\n",
    "    - replace each pixel by a linear combination of its neighbors\n",
    "    - e.g. the kernel is moved across the input image and for each pixel we generate a new pixel by an element-wise multiplication of the kernel and the region of the original image that is currently under the kernel and sum everything up to get the new pixel value\n",
    "    - example: smoothing an image with a gaussian kernel\n",
    "        - a gaussian kernel kind of takes the avg of the neighboring pixels, but with a higher weight for the pixels towards the center of the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "785d62bb0630fd558d898cfa75bc326e",
     "grade": false,
     "grade_id": "conv-theory-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Properties\n",
    "Is convolution linear or non-linear? Is it homogenous or inhomogenous? Proof your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97f9914348b57dcf233aea9425d13911",
     "grade": true,
     "grade_id": "conv-theory-a2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "There are linear and non-linear convolutions based on the functional evaluation of the neighboring pixels.\n",
    "\n",
    "In the lecture, we talked about linear, homogeneous convolutions.  \n",
    "The proof for homogenity is already part of the proof for linearity.\n",
    "\n",
    "**Linearity Proof:**\n",
    "\n",
    "The convolution defined by the local operator $L$ is linear if:\n",
    "\n",
    "**homogenity**: $L(ag) = a L(g)$:  \n",
    "\n",
    "$L(a \\cdot g(x, y)) = \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot a \\cdot g(x+i, y+j)$  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad = a \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot g(x+i, y+j)$  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad = a \\cdot L(g(x, y))$  \n",
    "\n",
    "**additivity**: $L(g_1 + g_2) = L(g_1) + L(g_2)$:  \n",
    "\n",
    "$L(g_1(x, y) + g_2(x, y)) = \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot (g_1(x+i, y+j) + g_2(x+i, y+j))$  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad = \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot g_1(x+i, y+j) + k(i+m, j+n) \\cdot g_2(x+i, y+j))$  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad = \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot g_1(x+i, y+j) + \\sum_{i \\in [-m, m]} \\sum_{j \\in [-n, n]} k(i+m, j+n) \\cdot g_2(x+i, y+j))$  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad = L(g_1) + L(g_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8065810ff49ce5f5de648fec49ba4f5e",
     "grade": false,
     "grade_id": "conv-theory-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Complexity\n",
    "\n",
    "Assume an image $g$ of size $M\\times N$ and a kernel $k$ of size $(2m+1)\\times(2n+1)$. How many operations (additions and multiplications) are required to compute a convoluted image $g\\ast k$ (of the same size as $g$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c6e7adab92c341780c045e00023fbae",
     "grade": true,
     "grade_id": "conv-theory-a3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "$M \\cdot N$ applications of the kernel (once for each pixel). For each application we have $(2m + 1)(2n + 1)$ multiplications and $(2m + 1)(2n + 1) - 1$ additions.  \n",
    "So, in total we have $MN(2((2m + 1)(2n+1)) - 1)$ operations.  \n",
    "$\\rightarrow$ $MN$ applications of complexity $O(mn)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08027a4887a3de1bfaa9ae8413fc5766",
     "grade": false,
     "grade_id": "conv-theory-q4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### d) Separability\n",
    "\n",
    "What is a separable kernel? Describe, how it can be applied more efficiently. Compute the number of operations for getting $g\\ast k$ (as in (c), but with a separable kernel $k$) and compare the results. Assume that the kernel is of size $m \\times n$ and the image is of size $M \\times N$. Compute the number of operations first for a single pixel and then extend your answer to the whole image. Ignore the normalization of the kernel, i.e. the fraction in front.\n",
    "\n",
    "Note that here we define the kernel size as $m \\times n$ as opposed to Assignment *1c)*. This is a shorter notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "015628beb7042ab70148278810a13c95",
     "grade": true,
     "grade_id": "conv-theory-a4",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Some kernels are separable which means that the kernel $k$ is a product of a row vector and a column vector:\n",
    "\n",
    "$k(i,j) = k^C(i) \\cdot k^R(j)$ with $k^R \\in \\mathbb{R^{1 \\times n}}, k^C \\in \\mathbb{R}^{m \\times 1}$\n",
    "\n",
    "That leads to a more efficient convolution by first using a $1 \\times n$-kernel and then a $m \\times 1$-kernel which reduces the computational effort from $O(mn)$ to $O(m + n)$.\n",
    "\n",
    "We still have $M \\cdot N$ applications of the kernels (once for each pixel), but we only need $n$ multiplications and $n-1$ additions for the row kernel\n",
    "and $m$ multiplications and $m-1$ additions for the column kernel. In total, we have $MN(n + n - 1 + m + m - 1)$ operations.  \n",
    "$\\rightarrow $MN applications of complexity $O(n + m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dc9ed13ccfe6a8521ea22bb5b7fb5ea",
     "grade": false,
     "grade_id": "conv-application",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Applying Convolution [4 Points]\n",
    "\n",
    "In this exercise you will apply convolution with different kernels. You may use the function `scipy.ndimage.filters.convolve` to solve this task. Check the documentation to learn how to use this function. In this assignment you do not have to implement the convolution yourself. Realize the following filters, describe their effect and possible applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a25c0fb618862b455e580b74a523105",
     "grade": false,
     "grade_id": "conv-application-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Box filter\n",
    "\n",
    "- linear filter in which each pixel in the resulting image has a value equal to the average value of its neighboring pixels in the input image\n",
    "- can be used for smoothing the image, e.g. for noise reduction (at cost of sharpness)\n",
    "- problem of hard boundary --> artifacts\n",
    "- with increasing filter size, the image gets increasingly blurry (bigger average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a37b17186698a80aecb509ccf2d269a",
     "grade": true,
     "grade_id": "conv-application-a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "from skimage import data\n",
    "from scipy import ndimage\n",
    "\n",
    "# Load an image\n",
    "#image = imread('some_file.png', pilmode = 'F')\n",
    "image = data.coins().astype(np.float32)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# box filter\n",
    "kernel = 1/9 * np.array([[1, 1, 1],\n",
    "                         [1, 1, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "filtered_image = ndimage.convolve(image, kernel)\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "a=fig.add_subplot(1,2,1)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('original')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,2,2)\n",
    "plt.imshow(filtered_image, cmap = 'gray')\n",
    "plt.title('box filter')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4ba96b41df47da693821157ca70efd5",
     "grade": false,
     "grade_id": "conv-application-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Gaussian filter\n",
    "\n",
    "You may try different filter sizes.\n",
    "\n",
    "- it's also averaging, but the central pixels are playing a stronger role compared to the rest (pixels that are farther away will not be taken into account as much)\n",
    "- a.k.a. gaussian blur / smoothing\n",
    "- reduce image noise (at cost of sharpness)\n",
    "- reduce detail\n",
    "- pre-processing for other algorithms\n",
    "- no artifacts, but blurring is not as strong as with the box filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cd73e3d844ae2d0a02303b2f3f9116e",
     "grade": true,
     "grade_id": "conv-application-a2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "from skimage import data\n",
    "\n",
    "# Load an image\n",
    "#image = imread('some_file.png', pilmode = 'F')\n",
    "image = data.coins().astype(np.float32)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# binomials are approximations of a gaussian distribution (the larger the better)\n",
    "# you can use pascal's triangle to generate binomial filters which can be used as approximations of gaussian filters\n",
    "\n",
    "# 2d binomial filters\n",
    "kernel_three = np.array([[1/16, 1/8, 1/16],\n",
    "                         [1/8, 1/4, 1/8],\n",
    "                         [1/16, 1/8, 1/16]])\n",
    "\n",
    "# not so good, because no central pixel\n",
    "kernel_four = np.array([[1/64, 3/64, 3/64, 1/64],\n",
    "                        [3/64, 9/64, 9/64, 3/64],\n",
    "                        [3/64, 9/64, 9/64, 3/64],\n",
    "                        [1/64, 3/64, 3/64, 1/64]])\n",
    "\n",
    "kernel_five = np.array([[1/256, 4/256, 6/256, 4/256, 1/256],\n",
    "                        [4/256, 16/256, 24/256, 16/256, 4/256],\n",
    "                        [6/256, 24/256, 36/256, 24/256, 6/256],\n",
    "                        [4/256, 16/256, 24/256, 16/256, 4/256],\n",
    "                        [1/256, 4/256, 6/256, 4/256, 1/256]])\n",
    "\n",
    "fig = plt.figure(figsize=(30,14))\n",
    "\n",
    "fig.add_subplot(1,4,1)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('original')\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,4,2)\n",
    "\n",
    "plt.imshow(ndimage.convolve(image, kernel_three), cmap = 'gray')\n",
    "plt.title('3x3 gaussian')\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.imshow(ndimage.convolve(image, kernel_four), cmap = 'gray')\n",
    "plt.title('4x4 gaussian')\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,4,4)\n",
    "plt.imshow(ndimage.convolve(image, kernel_five), cmap = 'gray')\n",
    "plt.title('5x5 gaussian')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38667765cad016dd2a187f672509dbdc",
     "grade": false,
     "grade_id": "conv-application-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Sobel filter\n",
    "\n",
    "Try horizontal, vertical, and diagonal sobel filters.\n",
    "\n",
    "- edge detection $\\rightarrow$ emphasizes edges (horizontally, vertically, diagonally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38fc340aeded67e5b4c374b84814b0e2",
     "grade": true,
     "grade_id": "conv-application-a3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "from skimage import data\n",
    "\n",
    "# Load an image\n",
    "#image = imread('some_file.png', pilmode = 'F')\n",
    "image = data.coins().astype(np.float32)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "sobel_horizontal = np.array([[-1, -2, -1],\n",
    "                             [0, 0, 0],\n",
    "                             [1, 2, 1]])\n",
    "\n",
    "sobel_vertical = np.array([[-1, 0, 1],\n",
    "                           [-2, 0, 2],\n",
    "                           [-1, 0, 1]])\n",
    "\n",
    "sobel_diag_one = np.array([[0, 1, 2],\n",
    "                           [-1, 0, 1],\n",
    "                           [-2, -1, 0]])\n",
    "\n",
    "sobel_diag_two = np.array([[-2, -1, 0],\n",
    "                           [-1, 0, 1],\n",
    "                           [0, 1, 2]])\n",
    "\n",
    "fig = plt.figure(figsize=(30,14))\n",
    "\n",
    "a=fig.add_subplot(1,5,1)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('original')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,5,2)\n",
    "plt.imshow(ndimage.convolve(image, sobel_horizontal, mode='constant', cval=0.0), cmap = 'gray')\n",
    "plt.title('sobel - horizontal')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,5,3)\n",
    "plt.imshow(ndimage.convolve(image, sobel_vertical), cmap = 'gray')\n",
    "plt.title('sobel - vertical')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,5,4)\n",
    "plt.imshow(ndimage.convolve(image, sobel_diag_one), cmap = 'gray')\n",
    "plt.title('sobel - diagonal1')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,5,5)\n",
    "plt.imshow(ndimage.convolve(image, sobel_diag_two), cmap = 'gray')\n",
    "plt.title('sobel - diagonal2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fa762722f0a2104b9bd779659ec4cab",
     "grade": false,
     "grade_id": "conv-application-q4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### d) Unsharp Mask\n",
    "\n",
    "One method to sharpen images is Unsharp Mask in which a negative unsharp mask is added to the original image as follows:\n",
    "\n",
    "$$\\text{Sharpened Image} = \\text{Original Image} + (\\text{Original Image} - \\text{Unsharp Image}) \\cdot \\text{Amount}$$\n",
    "\n",
    "The unsharp image can be computed by convolution with a Gaussian Kernel. Implement unsharp masking with a $5\\times5$ Gaussian Kernel and a sharpening amount of $1.5$. Use the allready defined gaussian kernel \"gauss_5\".\n",
    "\n",
    "Hint: To get good results the final images needs to be clipped to values between $0$ and $255$, i.e. all negative values are set to zero and all values bigger than $255$ are set to $255$.\n",
    "\n",
    "You may experiment with large or negative sharpening amounts.\n",
    "\n",
    "* Why is Unsharp Masking sharpening an image?\n",
    "* What is the difference between normalizing and clipping an image?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e146882a117bdaa1e93629f6afa3f6c0",
     "grade": true,
     "grade_id": "cell-86d3a7953faf8407",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- When we subtract the unsharp image from the original, we basically subtract the blurriness and end up with the parts that are high-contrast (difference).  \n",
    "If we add that (weighted with the amount), we basically strengthen the sharp parts.\n",
    "\n",
    "- Normalizing an image means that the range of pixel intensities gets changed. Clipping on the other hand is just the idea of keeping every pixel value inside the minimum and maximum intensity that can be represented, i.e. $[0, 255]$.\n",
    "\n",
    "notes:\n",
    "- increasing the sharpening amount only leads to good results up to a certain point (artifacts etc.)\n",
    "- negative sharpening amounts: blurring with artifacts (weakening the sharp parts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccc1f0d6573d20c00bef226b72e2ebb4",
     "grade": true,
     "grade_id": "conv-application-a4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "from skimage import data\n",
    "\n",
    "# Load an image\n",
    "#image = imread('some_file.png.jpg', mode='F')\n",
    "image = data.coins().astype(np.float32)\n",
    "\n",
    "# Define sharpening amount\n",
    "amount = 1.5\n",
    "\n",
    "# Define the filters:\n",
    "gauss_5 = 1/256 * np.asarray([[1,4,6,4,1],[4,16,24,16,4],[6,24,36,24,6],[4,16,24,16,4],[1,4,6,4,1]])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "unsharped_mask_image = ndimage.filters.convolve(image, gauss_5)\n",
    "diff_img = image - unsharped_mask_image\n",
    "np.clip(diff_img, 0, 255, diff_img)\n",
    "sharpened_img = image + diff_img * amount\n",
    "np.clip(sharpened_img, 0, 255, sharpened_img)\n",
    "\n",
    "fig = plt.figure(figsize=(30,14))\n",
    "\n",
    "a=fig.add_subplot(1,4,1)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('original')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,2)\n",
    "plt.imshow(unsharped_mask_image, cmap = 'gray')\n",
    "plt.title('unsharp mask')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,3)\n",
    "plt.imshow(diff_img, cmap = 'gray')\n",
    "plt.title('diff')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,4)\n",
    "plt.imshow(sharpened_img, cmap = 'gray')\n",
    "plt.title('sharpened image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0f2a9fcc68bf726b2cb6896e2870261",
     "grade": false,
     "grade_id": "conv-implementaion",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: Implementing Convolution [8 Points]\n",
    "\n",
    "Now implement your own 2-dimensional convolution function. The function should take an image and a kernel as argument and return an image of the same size, containing the result of convolving the image with the kernel.\n",
    "\n",
    "You may notice a problem at the boundaries of the image. Describe the problem and possible solutions. Implement at least one of them.\n",
    "\n",
    "Then apply your function with different kernels. Compare the results with [Assignment 2](#Assignment-2:-Applying-Convolution-[4-Points]).\n",
    "\n",
    "\n",
    "**Boundary Problem**  \n",
    "\n",
    "The problem occurs when applying the kernel to the edge pixels where the kernel overlaps the image. A common solution for the problem is to extend the image beyond its boundaries.\n",
    "There are several common approaches for that, e.g.:\n",
    "\n",
    "- reflect: input is extended by reflecting about the edge of the last pixel\n",
    "- constant: input is extended by filling all values beyond the edge with the same constant value\n",
    "- nearest: input is extended by replicating the last pixel\n",
    "- mirror: input is extended by reflecting about the center of the last pixel\n",
    "- wrap: input is extended by wrapping around to the opposite edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e97b2b28447f484b2fcb3141926a3ded",
     "grade": true,
     "grade_id": "conv-implementation-a",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "\n",
    "def my_convolve2d(img, kern):\n",
    "    \"\"\"Convolve an image with a kernel.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The image, provided as a two-dimensional array.\n",
    "        kern (np.ndarray): The kernel, also a two-dimensional array.\n",
    "        \n",
    "    Returns:\n",
    "        result (np.ndarray): The convolved image. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # store the image size for easier access\n",
    "    M,N = img.shape\n",
    "    # store the kernel size\n",
    "    m,n = kern.shape\n",
    "    # and also the half kernel size\n",
    "    mh, nh = (m//2, n//2)\n",
    "    \n",
    "    # Initialize the result matrix\n",
    "    result = np.zeros((M,N))\n",
    "    \n",
    "    # Compute the convolution\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    for x in range(M):\n",
    "        for y in range(N):\n",
    "            # (x,y) is current pixel in original image to apply kernel to\n",
    "            pixel = 0\n",
    "            for i in range(-mh, mh + 1):\n",
    "                for j in range(-nh, nh + 1):\n",
    "                    if x + i > 0 and y + j > 0 and x + i < M and y + j < N:\n",
    "                        pixel += kern[i + mh][j + nh] * img[x + i][y + j]\n",
    "                    else:\n",
    "                        # handle array borders: mode: 'constant', cval: 0.0\n",
    "                        pixel += kern[i + mh][j + nh] * 0.0\n",
    "            result[x][y] = pixel\n",
    "\n",
    "    return result\n",
    "\n",
    "# Apply your function to an image:\n",
    "# Try different filters, compare the results with Assignment 2\n",
    "\n",
    "# Load the image\n",
    "image = data.coins().astype(np.float32)\n",
    "\n",
    "box_filter = 1/9 * np.array([[1, 1, 1],\n",
    "                            [1, 1, 1],\n",
    "                            [1, 1, 1]])\n",
    "\n",
    "gaussian_filter = np.array([[1/16, 1/8, 1/16],\n",
    "                            [1/8, 1/4, 1/8],\n",
    "                            [1/16, 1/8, 1/16]])\n",
    "\n",
    "sobel_horizontal = np.array([[-1, -2, -1],\n",
    "                             [0, 0, 0],\n",
    "                             [1, 2, 1]])\n",
    "\n",
    "fig = plt.figure(figsize=(30,14))\n",
    "\n",
    "a=fig.add_subplot(1,4,1)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('original')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,2)\n",
    "plt.imshow(my_convolve2d(image, box_filter), cmap = 'gray')\n",
    "plt.title('box filter')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,3)\n",
    "plt.imshow(my_convolve2d(image, gaussian_filter), cmap = 'gray')\n",
    "plt.title('gaussian filter')\n",
    "plt.axis('off')\n",
    "\n",
    "a=fig.add_subplot(1,4,4)\n",
    "plt.imshow(my_convolve2d(image, sobel_horizontal), cmap = 'gray')\n",
    "plt.title('horizontal sobel')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('cv': conda)",
   "language": "python",
   "name": "python38664bitcvcondace24c6b5e63f40158ccc45b6baeafab5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}