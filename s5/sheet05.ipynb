{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07466f0ee100134f173327b26fa7ee71",
     "grade": false,
     "grade_id": "cell-9c8eb97b21def4b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Computer Vision (Winter Term 2020/21) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40973faf5c0b90d0cbfb8149ae4f3c7f",
     "grade": false,
     "grade_id": "cell-5a896fb58e2e26c8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 05: Segmentation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fa232beaeb2674800670e8d566a91de",
     "grade": false,
     "grade_id": "cell-b909516194670b69",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, December 5, 2020**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7715ed9b03e23c297e5544b747a11a5e",
     "grade": false,
     "grade_id": "cell-0f23fe4f5fc608a0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (Periodic functions) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy, does not give any points, and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b31c822376556fb6e7f8b071632d5d47",
     "grade": false,
     "grade_id": "cell-ea301a189131ace2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What are periodic functions? Can you provide a definition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92962ca5065f91326b7c70d91a36d8c3",
     "grade": true,
     "grade_id": "cell-c179a0d85e719ea5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5480c4d2077c1ee2f720d626ae408b",
     "grade": false,
     "grade_id": "cell-cd34893bcdd7d7c1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What are *amplitude*, *frequency*, *wave length*, and *phase* of a sine function? How can you change these properties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc57a43e8b1454e521a06a27fad5929",
     "grade": true,
     "grade_id": "cell-353f1c67a9fc45b7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d154bb8fab47720af8d625955a76bb3",
     "grade": false,
     "grade_id": "cell-20750512d8d75573",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** How are sine and cosine defined for complex arguments? In what sense does this generalize the real case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67376a2b51a678e94da2e8d0aa4bb3ad",
     "grade": true,
     "grade_id": "cell-877fd6d7323b1978",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da5587647775beecc7a3c6fab1d62374",
     "grade": false,
     "grade_id": "cell-34fbef915eea84d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Edge-based segmentation  [5 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gradients\n",
    "What is the gradient of a pixel? How do we calculate the first, how the second derivative of an image?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of a pixel is given by the difference in contrast to its neighboring pixels (4- or 8-neighborhood). The gradient points into the direction with highest divergence. We can imagine an image as a function consisting of two variables (x- and y-axes) and its color shading in each pixel as the outcome. The whole image presents a landscape of valleys and hills in respect to its shading and coloring. A sobel-filtered image presents the first derivative of each pixel while the laplace-filter creates the second derivative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1e38dad93bf74c05f54334f5664d5ce",
     "grade": false,
     "grade_id": "cell-509a7e125318987d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Edge linking\n",
    "\n",
    "Describe in your own words the idea of edge linking. What is the goal? Why does it not necessarily yield closed\n",
    "edge contours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bad2764a5f32203e07242adbe0efb4a0",
     "grade": true,
     "grade_id": "cell-17f4e8a096965ade",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Edge linking is a variant of **edge-based segmentation** that uses gradient magnitude to link edges.  \n",
    "The stronger the gradient value at position $(x, y)$, the higher the probability that it is a real edge and not noise.  \n",
    "If $(x, y)$ belongs to an edge, the idea is that there should be more edge pixels orthogonal to the gradient direction.\n",
    "\n",
    "**Goal:** Find segments by a search for boundaries between regions of different features.\n",
    "\n",
    "**TODO: Why not closed edge contours?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05aa93b3229752b06f8002351fbb6f0b",
     "grade": false,
     "grade_id": "cell-73c06fc018bbf674",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Zero crossings\n",
    "\n",
    "Explain what zero crossings are. Why does the detection of zero crossings always lead to closed contours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22995da75ee2212883d07d247a1a990b",
     "grade": true,
     "grade_id": "cell-d7d9e72d52085466",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "A zero-crossing in general is a point where the sign of a function changes, represented by an intercept of the axis in the graph of the function.  \n",
    "In our context, zero crossings of the second derivative correspond to edges.\n",
    "\n",
    "**TODO:** why lead to closed contours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a25a9436c4d3df82cdf9eaab635499a",
     "grade": false,
     "grade_id": "cell-e3873885045956b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Zero crossings (implementation)\n",
    "\n",
    "Provide an implementation of the zero crossing procedure described in (CV-07 slide 71). To get sensible results you should smooth the image before applying the Laplacian filter, e.g. using the Laplacian of a Gaussian (you may use buildin functions for the filterings steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04c9eb20c59f378aa2df81b08daaefc3",
     "grade": true,
     "grade_id": "cell-de9b4205b58d45298",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import shift\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "img = imread('images/swampflower.png').astype(float)\n",
    "img /= img.max()\n",
    "\n",
    "# Now compute edges and then zero crossings using the 4-neighborhood and the 8-neighborhood\n",
    "# YOUR CODE HERE\n",
    "\n",
    "def four_shift(edges):\n",
    "    x_shift = shift(edges, (1, 0))\n",
    "    y_shift = shift(edges, (0, 1))\n",
    "    return (edges * x_shift <= 0) + (edges * y_shift <= 0)\n",
    "\n",
    "def eight_shift(edges):\n",
    "    tmp = four_shift(edges)\n",
    "    xy_shift_one = shift(edges, (1, -1))\n",
    "    xy_shift_two = shift(edges, (1, 1))\n",
    "    return tmp + (edges * xy_shift_one <= 0) + (edges * xy_shift_two <= 0)\n",
    "\n",
    "smooth_img = filters.gaussian(img, sigma=5)\n",
    "edges = filters.laplace(smooth_img)\n",
    "\n",
    "zero_crossings_n4 = four_shift(edges)\n",
    "zero_crossings_n8 = eight_shift(edges)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.gray()\n",
    "\n",
    "plt.subplot(2,2,1); plt.axis('off'); plt.imshow(img); plt.title('original')\n",
    "plt.subplot(2,2,2); plt.axis('off'); plt.imshow(edges); plt.title('edges')\n",
    "plt.subplot(2,2,3); plt.axis('off'); plt.imshow(zero_crossings_n4); plt.title('zero crossings (N4)')\n",
    "plt.subplot(2,2,4); plt.axis('off'); plt.imshow(zero_crossings_n8); plt.title('zero crossings (N8)' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c262ca3bf9f121535e58851d390cd218",
     "grade": false,
     "grade_id": "cell-00b8626e22b568b7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Watershed transform  [5 Points]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfa76fe3befc7f6b97f6756eeaef0ab6",
     "grade": false,
     "grade_id": "cell-7554fc226cb5570a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Watershed transform\n",
    "\n",
    "Explain in your own words the idea of watershed transform. How do the two different approaches from the lecture work? Why does watershed transform always give a closed contour?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "019801168a994ed6958b176d32d2778b",
     "grade": true,
     "grade_id": "cell-eedef8dcca391a12",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Watershed transform finds segments included by edges. The gradient magnitude image represents the heights of the watershed as segment boundaries.  \n",
    "The water flows downhill to a local minimum and the result are segments enclosed by edges, but ignoring the differing strength of edges (noise).\n",
    "\n",
    "Two methods:\n",
    "- **rain**: compute for each pixel the local minimum (where the water gathers)\n",
    "- **flood**: starting at local minima, the groundwater floats the relief\n",
    "\n",
    "**TODO:** Why does watershed transform always give a closed contour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0dc64c88257d08678c389a8a9cb3af1b",
     "grade": false,
     "grade_id": "cell-8119b7b7b3efcacc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Implementation\n",
    "\n",
    "Now implement the watershed transform using the flooding approach (CV-07 slide 76, but note, that the algorithm presented there is somewhat simplified!). Obviously, buildin functions for computing watershed transform are not allowed, but all other functions may be used. In this example we appply the watershed transform to a distance transformed image, so you **do not** have to take the gradient image, but can apply the watershed transform directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae506712bd0caea676a2208aa92a7aef",
     "grade": true,
     "grade_id": "cell-9e15d7hjee9ad9ff28",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def watershed(img, step=1):\n",
    "    \"\"\"\n",
    "    Perform watershed transform on a grayscale image.\n",
    "    \n",
    "    Args:\n",
    "        img (ndarray): The grayscale image.\n",
    "        step (int): The rise of the waterlevel at each step. Default 1.\n",
    "        \n",
    "    Returns:\n",
    "        edges (ndarray): A binary image containing the watersheds.\n",
    "    \"\"\"\n",
    "\n",
    "    NO_LABEL = 0\n",
    "    WATERSHED = 1\n",
    "    new_label = 2\n",
    "\n",
    "    # initialize labels\n",
    "    label = np.zeros(img.shape, np.uint16)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    for h in range(int(img.max())):\n",
    "        for x in range(img.shape[0] - 1):\n",
    "            for y in range(img.shape[1] - 1):\n",
    "                if h >= img[x][y] and label[x][y] == 0:\n",
    "                    # flooded - 3 cases\n",
    "                    nl = get_neighbor_labels(label, x, y)\n",
    "                    # isolated\n",
    "                    if np.sum(nl) == 0:\n",
    "                        label[x][y] = new_label\n",
    "                    # segment\n",
    "                    elif np.sum(nl) == np.all(nl == nl[0]):\n",
    "                        label[x][y] = nl[0]\n",
    "                    # watershed\n",
    "                    else:\n",
    "                        label[x][y] = WATERSHED\n",
    "\n",
    "    for x in range(label.shape[0]):\n",
    "        for y in range(label.shape[1]):\n",
    "            if label[x][y] == WATERSHED:\n",
    "                label[x][y] = 0\n",
    "            else:\n",
    "                label[x][y] = 1\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_neighbor_labels(label, x, y):\n",
    "    return [\n",
    "        label[x - 1][y - 1], label[x][y - 1], label[x + 1][y - 1], label[x - 1][y],\n",
    "        label[x + 1][y], label[x - 1][y + 1], label[x][y + 1], label[x + 1][y + 1]\n",
    "    ]\n",
    "\n",
    "img = imageio.imread('images/dist_circles.png', pilmode='L')\n",
    "\n",
    "plt.gray()\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(watershed(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0f8e19d0ab8d7812e10976a27cf4282",
     "grade": false,
     "grade_id": "cell-0c422113ff9318d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Application: maze\n",
    "\n",
    "You can use watershed transform to find your way through a maze. To do so, first apply a distance transform to the maze and then flood the result. The watershed will show you the way through the maze. Explain why this works.\n",
    "You can use build-in functions instead of your own watershed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8025f19c0dd33c816a1fe01a9472b3fe",
     "grade": true,
     "grade_id": "cell-1c20c149aa872621",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "%matplotlib inline\n",
    "\n",
    "img = imageio.imread('images/maze2.png', pilmode = 'L') # 'maze1.png' or 'maze2.png'\n",
    "\n",
    "result = img[:, :, np.newaxis].repeat(3, 2)\n",
    "# YOUR CODE HERE\n",
    "dt = distance_transform_edt(img)\n",
    "water = watershed(dt)\n",
    "result[water == 1] = (255, 0, 0)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Solution')\n",
    "plt.axis('off')\n",
    "plt.gray()\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be419afd8e5beea6691c6e3c7d5736cf",
     "grade": true,
     "grade_id": "cell-1e1faf216fbeaf2a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The solution path is the watershed between the catchment basins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63afb9fb95d555d09e3c691c5164ae0f",
     "grade": false,
     "grade_id": "cell-88b773263ced806b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: $k$-means segmentation [5 Points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8389ef310b1adf4841cca484c85eb97f",
     "grade": false,
     "grade_id": "cell-968700f39fdd5d90",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain the idea of $k$-means clustering and how it can be used for segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f794dde416568a5cf53cfb0d43d6d398",
     "grade": true,
     "grade_id": "cell-39516774ed896353",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Color segmentation in general is used to find segments of constant color.  \n",
    "$k-$Means in general is used to separate data into $k$ clusters of similar properties represented by a cluster center.\n",
    "\n",
    "$k-$Means for color segmentation starts with with $k$ random RGB values as cluster centers and assigns each RGB value in the image to its closest\n",
    "cluster center based on the RGB difference. Afterwards, a new center is computed for each cluster based on its average RGB value.  \n",
    "It's an iterative procedure of the two steps 'center computation' and 'cluster assignment update' until convergence up to a certain threshold is reached.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd6eace72d9e7e272b1485c8218d244c",
     "grade": false,
     "grade_id": "cell-ef26310265357445",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Implement k-means clustering for color segmentation of an RGB image (no use of `scipy.cluster.vq.kmeans` or similar functions allowed here, but you may use functions like `numpy.mean`, `scipy.spatial.distance.pdist` and similar utility functions). Stop calculation when center vectors do not change more than a predefined threshold. Avoid empty clusters by re-initializing the corresponding center vector. (Empirically) determine a good value for $k$ for clustering the image 'peppers.png'.\n",
    "**Bonus** If you want you can visualize the intermediate steps of the clustering process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cd64cdcab3273b8925f3464dad0733a",
     "grade": false,
     "grade_id": "cell-519f9fdb2f560fe1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "First lets take a look at how our image looks in RGB colorspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b008b4bd90a590ac353822bdebe8099",
     "grade": false,
     "grade_id": "cell-b01d17a292a4b149",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = imread('images/peppers.png')\n",
    "vec = img.reshape((-1, img.shape[2]))\n",
    "vec_scaled = vec / 255\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ret = ax.scatter(vec[:, 0], vec[:, 1], vec[:, 2], c=vec_scaled, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0a44150e44fe056f907d1b497832810",
     "grade": true,
     "grade_id": "cell-7c3eb548caa02d4d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from IPython import display\n",
    "from imageio import imread\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def kmeans_rgb(img, k, threshold=0, do_display=None):\n",
    "    \"\"\"\n",
    "    k-means clustering in RGB space.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): an RGB image\n",
    "        k (int): the number of clusters\n",
    "        threshold (float): Maximal change for convergence criterion.\n",
    "        do_display (bool): Whether or not to plot, intermediate steps.\n",
    "        \n",
    "    Results:\n",
    "        cluster (numpy.ndarray): an array of the same size as `img`,\n",
    "            containing for each pixel the cluster it belongs to\n",
    "        centers (numpy.ndarray): 'number of clusters' x 3 array. \n",
    "            RGB color for each cluster center.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # initialize random cluster centers (k random rgb tuples)\n",
    "    centers = np.array([np.random.randint(255, size=3) for _ in range(k)])\n",
    "    # list of rgb values in img\n",
    "    rgb_list = [[img[x][y][0], img[x][y][1], img[x][y][2]] for x in range(img.shape[0]) for y in range(img.shape[1])]\n",
    "\n",
    "    change = np.inf\n",
    "\n",
    "    while change > threshold:\n",
    "        change = 0\n",
    "        # compute distance between each pair of the two collections of inputs\n",
    "        rgb_dist_to_centers = distance.cdist(rgb_list, centers)\n",
    "        # assign closest cluster center to each rgb value\n",
    "        cluster_for_each_rgb = np.array([np.argmin(distances) for distances in rgb_dist_to_centers])\n",
    "\n",
    "        for i in range(k):\n",
    "            if i in cluster_for_each_rgb:\n",
    "                # determine colors that are assigned to the currently considered cluster\n",
    "                colors = [rgb_list[x] for x in range(len(rgb_list)) if cluster_for_each_rgb[x] == i]\n",
    "\n",
    "                # update cluster center\n",
    "                new_center = []\n",
    "                for channel in range(3):\n",
    "                    avg = 0\n",
    "                    for x in colors:\n",
    "                        avg += x[channel]\n",
    "                    new_center.append(int(avg / len(colors)))\n",
    "\n",
    "            else:\n",
    "                # re-initialize center\n",
    "                new_center = np.random.randint(255, size=3)\n",
    "            \n",
    "            change += distance.cdist([centers[i]], [new_center])\n",
    "            centers[i] = new_center\n",
    "\n",
    "    return cluster_for_each_rgb.reshape((img.shape[0], img.shape[1])), centers\n",
    "\n",
    "img = imread('images/peppers.png')\n",
    "\n",
    "cluster, centers = kmeans_rgb(img, k=7, threshold=0, do_display=True)\n",
    "plt.imshow(centers[cluster])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15aae981792510e81229bb55428a6f8b",
     "grade": false,
     "grade_id": "cell-b06ae459499022d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Now do the same in the HSV space (remember its special topological structure). Check if you can improve the results by ignoring some of the HSV channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bacfb7489d39f26e802b19f8c4bd140",
     "grade": true,
     "grade_id": "cell-2f871a555d5f45c4",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from skimage import color\n",
    "from imageio import imread\n",
    "%matplotlib inline\n",
    "# from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "\n",
    "img = imread('images/peppers.png', pilmode = 'RGB')\n",
    "\n",
    "def kmeans_hsv(img, k, threshold = 0):\n",
    "    \"\"\"\n",
    "    k-means clustering in HSV space.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): an HSV image\n",
    "        k (int): the number of clusters\n",
    "        threshold (float): \n",
    "        \n",
    "    Results:\n",
    "        cluster (numpy.ndarray): an array of the same size as `img`,\n",
    "            containing for each pixel the cluster it belongs to\n",
    "        centers (numpy.ndarray): an array\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # initialize random cluster centers (k random hsv tuples)\n",
    "    centers = np.array([np.random.uniform(0, 1, size=3) for _ in range(k)])\n",
    "    # list of rgb values in img\n",
    "    hsv_list = [[img[x][y][0], img[x][y][1], img[x][y][2]] for x in range(img.shape[0]) for y in range(img.shape[1])]\n",
    "\n",
    "    change = np.inf\n",
    "\n",
    "    while change > threshold:\n",
    "        change = 0\n",
    "        # compute distance between each pair of the two collections of inputs\n",
    "        hsv_dist_to_centers = distance.cdist(hsv_list, centers)\n",
    "        # assign closest cluster center to each hsv value\n",
    "        cluster_for_each_hsv = np.array([np.argmin(distances) for distances in hsv_dist_to_centers])\n",
    "\n",
    "        for i in range(k):\n",
    "            if i in cluster_for_each_hsv:\n",
    "                # determine colors that are assigned to the currently considered cluster\n",
    "                colors = [hsv_list[x] for x in range(len(hsv_list)) if cluster_for_each_hsv[x] == i]\n",
    "\n",
    "                # update cluster center\n",
    "                new_center = []\n",
    "                for channel in range(3):\n",
    "                    avg = 0\n",
    "                    for x in colors:\n",
    "                        avg += x[channel]\n",
    "                    new_center.append(avg / len(colors))\n",
    "\n",
    "            else:\n",
    "                # re-initialize center\n",
    "                new_center = np.random.uniform(0, 1, size=3)\n",
    "            \n",
    "            change += distance.cdist([centers[i]], [new_center])\n",
    "            centers[i] = new_center\n",
    "\n",
    "    return cluster_for_each_hsv.reshape((img.shape[0], img.shape[1])), centers\n",
    "\n",
    "\n",
    "img_hsv = color.rgb2hsv(img)\n",
    "k = 7\n",
    "theta = 0.01\n",
    "\n",
    "cluster, centers_hsv = kmeans_hsv(img_hsv[:,:,:], k, theta)\n",
    "if (centers_hsv.shape[1] == 3):\n",
    "    plt.imshow(color.hsv2rgb(centers_hsv[cluster]))\n",
    "else:\n",
    "    plt.gray()\n",
    "    plt.imshow(np.squeeze(centers_hsv[cluster]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9230048ccabbd2db8733eb762331d01",
     "grade": false,
     "grade_id": "cell-ba8ee2b9d1e1b532",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 4: Interactive Region Growing [5 Points]\n",
    "\n",
    "Implement flood fill as described in (CV07 slides 123ff.).\n",
    "\n",
    "In a recursive implementation the floodfill function is called for the seed pixel. In the function a recursive call for the four neighbouring pixels is made, if the color of the pixel, the function is called with, is similar to the seed color. If this is the case the pixel is added to the region. [Other](https://en.wikipedia.org/wiki/Flood_fill) more elegant solutions exist aswell.\n",
    "\n",
    "The function `on_press` is called when a mouse button is pressed inside the canvas. From there call `floodfill`. Use the filtered hsv image `img_filtered` for your computation, and show the computed region around the seed point (the position where the mousebutton was pressed) in the original image. You may use a mask to save which pixels belong the the region (and to save which pixels you already visited). \n",
    "\n",
    "Hint: If you can not see the image, try restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c05ae1dbb529b482c41ac8a9a347efe3",
     "grade": true,
     "grade_id": "cell-cdade115569170d14",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import imageio\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "import scipy.ndimage as ndimage\n",
    "from sys import setrecursionlimit\n",
    "from scipy.spatial import distance\n",
    "\n",
    "threshold = .08;\n",
    "\n",
    "setrecursionlimit(100000)\n",
    "\n",
    "def floodfill(img, mask, x, y, color):\n",
    "    \"\"\"Recursively grows region around seed point\n",
    "    \n",
    "    Args: \n",
    "        img (ndarray): The image in which the region is grown\n",
    "        mask (boolean ndarray): Visited pixels which belong to the region.\n",
    "        x (uint): X coordinate of the pixel. Checks if this pixels belongs to the region\n",
    "        y (uint): Y coordinate of the pixel.\n",
    "        color (list): The color at the seed position\n",
    "\n",
    "    Return:\n",
    "        mask (boolean ndarray): mask containing region\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if distance.cdist([img[x][y]], [color]) < threshold:\n",
    "        mask[x,y] = True\n",
    "        eight_neighbourhood = get_neighbors(x, y)\n",
    "        for x, y in eight_neighbourhood:\n",
    "            if not mask[x][y]:\n",
    "                mask = floodfill(img, mask, x, y, color)\n",
    "    return mask\n",
    "    \n",
    "def get_neighbors(x, y):\n",
    "    return [\n",
    "        (x - 1, y - 1), (x, y - 1), (x + 1, y - 1), (x - 1, y),\n",
    "        (x + 1, y), (x - 1, y + 1), (x, y + 1), (x + 1, y + 1)\n",
    "    ]\n",
    "\n",
    "def on_press(event):\n",
    "    \"\"\"Mouse button press event handler\n",
    "    \n",
    "    Args:\n",
    "        event: The mouse event\n",
    "    \"\"\"\n",
    "    y = math.floor(event.xdata)\n",
    "    x = math.floor(event.ydata)\n",
    "    color = img_filtered[x, y, :]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    mask = floodfill(img_filtered, np.zeros((img.shape[0], img.shape[1])), x, y, color)\n",
    "    img[mask == True] = (255, 255, 255)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "\n",
    "def fill_from_pixel(img, img_filtered, x,y):\n",
    "    \"\"\" Calls floodfill from a pixel position\n",
    "    \n",
    "    Args:\n",
    "        img (ndarray): IO image on which fill is drawn.\n",
    "        img_filtered (ndarray): Processing image on which floodfill is computed.\n",
    "        x (uint): Coordinates of pixel position.\n",
    "        y (uint): Coordinates of pixel position.\n",
    "\n",
    "    Returns:\n",
    "        img (ndarray): Image with grown area in white\n",
    "    \"\"\"\n",
    "    mask = np.zeros((img.shape[0],img.shape[1]))\n",
    "    color = img_filtered[x,y, :]\n",
    "    mask = floodfill(img_filtered, mask, x, y, color)\n",
    "    img[mask] = (255, 255, 255)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "img = imageio.imread('images/peppers.png')\n",
    "img_hsv = color.rgb2hsv(img)\n",
    "img_filtered = ndimage.median_filter(img_hsv, 5)\n",
    "#img = fill_from_pixel(img, img_filtered, 200, 300) # Comment in to deactivate simple testing at fixed position\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(img)\n",
    "fig.canvas.mpl_connect('button_press_event', on_press)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('cv': conda)",
   "language": "python",
   "name": "python38664bitcvcondace24c6b5e63f40158ccc45b6baeafab5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}