{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17f3d8fcdb9021f06c899069cd23e169",
     "grade": false,
     "grade_id": "cell-60aa580d9d920dba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabrück University - Computer Vision (Winter Term 2020/21) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland, Ludwig Schallner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e915f7889cdfa020420ab4041718d2fb",
     "grade": false,
     "grade_id": "cell-d9e6599459b0ba4d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 11: Object recognition: PCA and Interest Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a6a5a4fa45d17e62e884199b16c107d",
     "grade": false,
     "grade_id": "cell-917ded279d27040b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, January 30, 2021**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d8cac965efa5ca2e705d4e0db66446e",
     "grade": false,
     "grade_id": "cell-pca",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1: Pattern Recognition and PCA [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87ba9f10c5306ed6f20123ec176417ad",
     "grade": false,
     "grade_id": "cell-pca-a-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What are the goals of *pattern recognition*? How can they be achieved? What are the problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da9027a58eb8dd3542a67db8889c6fdf",
     "grade": true,
     "grade_id": "cell-pca-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d0018d586e6246d76b54c31adc94277",
     "grade": false,
     "grade_id": "cell-pca-b-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is *principal component analysis*? How is it related to pattern recognition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b318f0c31c35f5294c27ee500be50871",
     "grade": true,
     "grade_id": "cell-pca-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff4056d5948e139f7608b4cbb27dc8be",
     "grade": false,
     "grade_id": "cell-pca-c-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Explain how principal components can be computed? Then implement a function that performs the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af40ccf763984f788e05787671e57082",
     "grade": true,
     "grade_id": "cell-pca-c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ae0a1ad727211764dd60c2f5cf6a61d",
     "grade": true,
     "grade_id": "cell-pca-c-implementation",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pca(data):\n",
    "    \"\"\"\n",
    "    Perform principal component analysis.\n",
    "    \n",
    "    Args:\n",
    "        data (ndarray): an array of shape (n,k),\n",
    "        meaning n entries with k dimensions\n",
    "        \n",
    "    Returns: two arrays\n",
    "        pc (ndarray): array of shape (k,k) holding the principal components in its columns.\n",
    "        var (ndarray): k-vector holding the corresponding variances, in descending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace the following two lines by your code ...\n",
    "    pc = np.random.randn(data.shape[1],data.shape[1])\n",
    "    var = np.random.rand(data.shape[1])\n",
    "    # YOUR CODE HERE\n",
    "    return pc, var\n",
    "\n",
    "# generate some random data\n",
    "np.random.seed(23)\n",
    "data = np.random.multivariate_normal([0,0], cov = [[1, .55], [.55, .5]], size=300)\n",
    "\n",
    "# compute the principal components\n",
    "pc, var = pca(data)\n",
    "mean = data.mean(axis=0)\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-2.5,2.5)\n",
    "plt.scatter(*data.T)\n",
    "plt.quiver(*mean[np.newaxis].repeat(2,axis=0).T, *(np.sqrt(var)*pc), color='red', scale=1, scale_units='xy')\n",
    "plt.show()\n",
    "\n",
    "# sanity check\n",
    "assert np.allclose(var, [1.216, 0.137], rtol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10280580ebc0e79fdd192da4b884386e",
     "grade": false,
     "grade_id": "cell-d4c528e622d59ef6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2: Eigenfaces [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f57ff5adf3e1b7d04ff909782096eb0",
     "grade": false,
     "grade_id": "cell-94ec3cfcfec0e7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Import the images from the directory `images/trainimgs` into an numpy array using the function \n",
    "`read_images_from_directory` provided in the cell below. Display the images and the corresponding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32ea68cf57b861c843342ad1a0798f74",
     "grade": true,
     "grade_id": "cell-471f722946eed0b9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_images_from_directory(directory, suffix, shape):\n",
    "    \"\"\"\n",
    "    Read all images found in DIRECTORY with given file\n",
    "    name SUFFIX. All images should have the same SHAPE,\n",
    "    specified as (rows,columns).\n",
    "    \n",
    "    Args:\n",
    "        directory (string): Name of input directory.\n",
    "        suffix (string): File type suffix.\n",
    "        shape (tuple): Shape of images to be loaded.\n",
    "    \n",
    "    Returns:\n",
    "        images (ndarray): A numpy array of shape m*rows*columns (from shape)\n",
    "        names (list): A list of corresponding image names.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the image array and name list\n",
    "    #images = np.empty((0, *shape))\n",
    "    images = np.empty((0, ) + shape)\n",
    "    names = []\n",
    "\n",
    "    # now loop through all image files in the directory\n",
    "    for file_name in glob.glob(directory + os.sep + '*.' + suffix):\n",
    "        if os.path.isfile(file_name):\n",
    "\n",
    "            # load each image (as double)\n",
    "            img = plt.imread(file_name)\n",
    "\n",
    "            # check for correct size\n",
    "            if img.shape == shape:\n",
    "                images = np.append(images, img.reshape((1, ) + shape), axis=0)\n",
    "                names.append(os.path.basename(file_name))\n",
    "            else:\n",
    "                print(\n",
    "                    'warning: Image \"' + file_name +\n",
    "                    '\" with wrong size will be ignored!',\n",
    "                    file=sys.stderr)\n",
    "\n",
    "    return images, names\n",
    "\n",
    "\n",
    "# image file suffix\n",
    "suffix = 'pgm'\n",
    "\n",
    "# image size\n",
    "img_shape = (192, 168)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd0762f3328bdde0693bd6554490650",
     "grade": false,
     "grade_id": "ex-eigenface-pca-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Use PCA to compute the eigenfaces (i.e. the eigenvectors of the face images). You may use your PCA function from Exercise 1c or some build in function. Explain what kind of input PCA expects, and how that fits to our images (you may have to `reshape` the images!). Finally, display the eigenfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b21646aaeb84b3ff958d9ffc0624bfa5",
     "grade": true,
     "grade_id": "cell-a8ca9a7fbbdedb2f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff1e319c2a7470adec5f61d0c8fe031c",
     "grade": false,
     "grade_id": "cell-c54ec5985375835f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Now project the training face images into the eigenspace to calculate their ”feature vectors”,\n",
    "i.e. a representation with significantly lower dimension. For the projection of the face images,\n",
    "they have to be centered first, i.e. the mean face vector has to be subtracted. Store the mean face in some vector (`mean_face`) and the representation achieved in some array (`face_db`). Finally restore the images from `face_db` and display them alongside the original image. Try out the effect of changing the number of eigenfaces to be used (`num_eigenfaces`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa115dd06eb2fa02ec975a7e082c5517",
     "grade": true,
     "grade_id": "cell-43eaeder3c18070c8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# number of eigenfaces to be used\n",
    "num_eigenfaces = 19\n",
    "\n",
    "# Remark: a value of 20 (theoretical perfect reconstruction) may suffer from numerical\n",
    "# instability (the last eigenface may introduce noise).\n",
    "# However, a value of 19 suffices for almost perfect reconstruction ...\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6d7cd5da56909f50364734682538c2f",
     "grade": false,
     "grade_id": "ex-eigenface-recognize",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** Implement the function `recognize_face` that recognizes a face from that database by calculating the euclidean distance of this face feature vector to all of the training feature vectors from the database. The feature vector with the smallest distance represents the winner category. Check your implementation by recognizing the images from the training set (they should be recognized without error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bea09983cd298ca05caed71293be8c23",
     "grade": true,
     "grade_id": "cell-55d01bed03c2d1ca2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def recognize_face(face, eigenfaces, mean_face, face_db):\n",
    "    \"\"\"\n",
    "    Recognize a face from a face database.\n",
    "    and return the index of the best matching database entry.\n",
    "\n",
    "    The FACE is first centered and projected into the eigeface\n",
    "    space provided by EIGENFACES. Then the best match is found\n",
    "    according to the euclidean distance in the eigenface space.\n",
    "    \n",
    "    Args:\n",
    "        face (ndarray): Face to be recognised.\n",
    "        eigenfaces (ndarray): Array of eigenfaces.\n",
    "        mean_face (ndarray): Average face.\n",
    "        face_db (ndarray): Database of faces projectected into Eigenface space.\n",
    "        \n",
    "    Returns:\n",
    "        index (uint): Position of the best matching face in face_db.\n",
    "    \"\"\"\n",
    "    index = -1\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "# ... and now check your function on the training set ...\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Now classify the images in directory `images/testimg/`. Try to reduce the number of principal components\n",
    "used. How many PCs are necessary to still achieve perfect classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc8d190a5cd8113f50e0911b0f9eac45",
     "grade": true,
     "grade_id": "cell-47ccaee3973f6ac4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_imgs, test_names = read_images_from_directory('images/testimg', suffix,\n",
    "                                                   img_shape)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b967482ba23f59c54c51d053ecd34ac",
     "grade": false,
     "grade_id": "cell-968c945b0dc138ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3: Local features and interest points [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82eadf947382a48bb4ec9d672aa59894",
     "grade": false,
     "grade_id": "cell-54385603796cbdc5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain in your own words: What are *local features*? How are they used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcccec95a733b8592ef282312430151d",
     "grade": true,
     "grade_id": "cell-9ab13a0e8484d6b9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "621e3785e27c2a56e40841056f9617a7",
     "grade": false,
     "grade_id": "cell-9a58a036bbdcba63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "solution": "hidden"
   },
   "source": [
    "**b)** What are *interest points* and what are they used for? What properties are desirable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6d83145851e94b3985ba286eb6a0540",
     "grade": true,
     "grade_id": "cell-b964929c6f2d5419",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": "hidden"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd0b08842c08479ae3d81943902b80d9",
     "grade": false,
     "grade_id": "cell-bffcd57e4ade7360x",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4: Computing interest points [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "080280cd532a1a4c48ad75595af6b302",
     "grade": false,
     "grade_id": "cell-moravec-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain in your own words the idea of the Moravec IP operator. What are its properties? Implement this IP operator and apply it to the image `lighthouse.png`. Try different window sizes and threshold values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f71a7dbedc335281ea82e554074fcdd",
     "grade": true,
     "grade_id": "cell-e5a892a0e5b57489",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "105cd30bed328ed5ef0b1276e1f93395",
     "grade": true,
     "grade_id": "cell-moravec-a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imageio.imread('images/lighthouse.png', pilmode='F')\n",
    "\n",
    "window_size = 3\n",
    "threshold = .2\n",
    "\n",
    "def moravec(img, window_size):\n",
    "    \"\"\"Moravec corner detector.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    img: np.ndarray\n",
    "        The input image\n",
    "    window_size: int\n",
    "        The size of the window to consider\n",
    "\n",
    "    Results\n",
    "    -------\n",
    "    response: np.ndarray\n",
    "        Response (of the same size as img), indicating interest points.\n",
    "    \"\"\"\n",
    "    response = np.zeros_like(img)\n",
    "    # YOUR CODE HERE\n",
    "    return response\n",
    "\n",
    "#response = moravec(img, window_size)\n",
    "response = moravec2(img, window_size)\n",
    "\n",
    "thresholded = np.zeros_like(response)\n",
    "thresholded[response > threshold] = 1\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1); plt.imshow(img, cmap='gray'); plt.title('Original')\n",
    "plt.subplot(2,2,2); plt.imshow(response, cmap='viridis'); plt.title('Moravec \"heatmap\"')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3); plt.imshow(thresholded, cmap='gray'); plt.title(f'Thresholded (>{threshold})')\n",
    "plt.subplot(2,2,4); plt.imshow(img[1:-1,:-1], cmap='gray'); plt.title('Corners')\n",
    "mask = np.zeros(thresholded.shape + (4,), dtype=np.int)\n",
    "mask[:,:,0] = 255\n",
    "mask[:,:,3] = thresholded*255\n",
    "plt.imshow(mask, interpolation='none')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c59a8fc69fc6f8979b64dd6de21f197",
     "grade": false,
     "grade_id": "cell-harris-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** How does the Harris corner detector work and in what sense does it improve the Moravec IP operator. Implement the Harris corner detector and apply it to `lighthouse.png`. Again, try different \"window sizes\" (values for $\\sigma$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caeee663722a27d0636dde08ede71424",
     "grade": true,
     "grade_id": "cell-d51a9747dd39f80b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "231501e51e2e9c10c85af8605f4ab16b",
     "grade": true,
     "grade_id": "cell-harris-a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "k = .04\n",
    "window_size = 3\n",
    "\n",
    "img = imageio.imread('images/lighthouse.png', pilmode='F')/255.\n",
    "\n",
    "def harris(img, window_size=3, k=0.04):\n",
    "    \"\"\"Harris corner detector.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    img: np.ndarray\n",
    "        The input image\n",
    "    window_size: int\n",
    "        The size of the window to consider\n",
    "    k: float\n",
    "        The parameter k\n",
    "        \n",
    "    Results\n",
    "    -------\n",
    "    response: np.ndarray\n",
    "        Response (of the same size as img), indicating interest points.\n",
    "    \"\"\"\n",
    "    response = np.zeros_like(img)\n",
    "    # YOUR CODE HERE\n",
    "    return response\n",
    "\n",
    "response = harris(img, window_size, k)\n",
    "corners = response.copy()        \n",
    "corners[response<0] = 0\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1); plt.imshow(img, cmap='gray'); plt.title(\"Original\")\n",
    "plt.subplot(2,2,2); plt.imshow(response, cmap='viridis'); plt.title('Harris \"heatmap\"')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3); plt.imshow((corners**.25), cmap='gray'); plt.title(f\"Thresholded (<0)\")\n",
    "plt.subplot(2,2,4); plt.imshow(img, cmap='gray'); plt.title('Corners')\n",
    "mask = np.zeros(corners.shape + (4,), dtype=np.int)\n",
    "mask[:,:,0] = 255\n",
    "mask[:,:,3] = (response>0)*255\n",
    "plt.imshow(mask, interpolation='none')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
