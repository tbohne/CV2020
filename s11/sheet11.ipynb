{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60aa580d9d920dba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabrück University - Computer Vision (Winter Term 2020/21) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland, Ludwig Schallner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9e6599459b0ba4d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 11: Object recognition: PCA and Interest Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-917ded279d27040b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, January 30, 2021**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-pca",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1: Pattern Recognition and PCA [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-pca-a-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What are the goals of *pattern recognition*? How can they be achieved? What are the problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-pca-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The goal of pattern recognition is to get a symbolic description from sensor data.\n",
    "\n",
    "It can be achieved following the standard architecture:\n",
    "* world -> Sensor -> feature extraction -> classification\n",
    "\n",
    "Problems:\n",
    "* No sharp description of classes and incomplete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-pca-b-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is *principal component analysis*? How is it related to pattern recognition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-pca-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "With PCA we can find a new basis for our dataset. The basis vectors can be ordered by maximun variance / minimun reconstruction error. \n",
    "In the best case each basis vector corresponds to a interpretable feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-pca-c-question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Explain how principal components can be computed? Then implement a function that performs the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-pca-c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Principal components are the eigenvalues of the covariance matrix of a dataset. The eigenvalues give the ordering of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-pca-c-implementation",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pca(data):\n",
    "    \"\"\"\n",
    "    Perform principal component analysis.\n",
    "    \n",
    "    Args:\n",
    "        data (ndarray): an array of shape (n,k),\n",
    "        meaning n entries with k dimensions\n",
    "        \n",
    "    Returns: two arrays\n",
    "        pc (ndarray): array of shape (k,k) holding the principal components in its columns.\n",
    "        var (ndarray): k-vector holding the corresponding variances, in descending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace the following two lines by your code ...\n",
    "    pc = np.random.randn(data.shape[1],data.shape[1])\n",
    "    var = np.random.rand(data.shape[1])\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    # Center the data (subtract the mean along columns).\n",
    "    centered_data = data - data.mean(axis=0)\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = centered_data.T @ centered_data/(len(data)-1)\n",
    "    \n",
    "    # Computing eigenvalues and eigenvectors of covariance matrix.\n",
    "    # Attention: not always sorted.\n",
    "    eigenvals, eigenvecs = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # Sort in order of descending magnitude\n",
    "    idx = np.argsort(eigenvals)[::-1]\n",
    "    pc, var = eigenvecs[:,idx], eigenvals[idx]\n",
    "    \n",
    "    # END SOLUTION\n",
    "    return pc, var\n",
    "\n",
    "# generate some random data\n",
    "np.random.seed(23)\n",
    "data = np.random.multivariate_normal([0,0], cov = [[1, .55], [.55, .5]], size=300)\n",
    "\n",
    "# compute the principal components\n",
    "pc, var = pca(data)\n",
    "mean = data.mean(axis=0)\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-2.5,2.5)\n",
    "plt.scatter(*data.T)\n",
    "plt.quiver(*mean, *(np.sqrt(var)*pc), color='red', scale=1, scale_units='xy')\n",
    "plt.show()\n",
    "\n",
    "# sanity check\n",
    "assert np.allclose(var, [1.216, 0.137], rtol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4c528e622d59ef6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2: Eigenfaces [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-94ec3cfcfec0e7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Import the images from the directory `images/trainimgs` into an numpy array using the function \n",
    "`read_images_from_directory` provided in the cell below. Display the images and the corresponding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-471f722946eed0b9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_images_from_directory(directory, suffix, shape):\n",
    "    \"\"\"\n",
    "    Read all images found in DIRECTORY with given file\n",
    "    name SUFFIX. All images should have the same SHAPE,\n",
    "    specified as (rows,columns).\n",
    "    \n",
    "    Args:\n",
    "        directory (string): Name of input directory.\n",
    "        suffix (string): File type suffix.\n",
    "        shape (tuple): Shape of images to be loaded.\n",
    "    \n",
    "    Returns:\n",
    "        images (ndarray): A numpy array of shape m*rows*columns (from shape)\n",
    "        names (list): A list of corresponding image names.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the image array and name list\n",
    "    #images = np.empty((0, *shape))\n",
    "    images = np.empty((0, ) + shape)\n",
    "    names = []\n",
    "\n",
    "    # now loop through all image files in the directory\n",
    "    for file_name in glob.glob(directory + os.sep + '*.' + suffix):\n",
    "        if os.path.isfile(file_name):\n",
    "\n",
    "            # load each image (as double)\n",
    "            img = plt.imread(file_name)\n",
    "\n",
    "            # check for correct size\n",
    "            if img.shape == shape:\n",
    "                images = np.append(images, img.reshape((1, ) + shape), axis=0)\n",
    "                names.append(os.path.basename(file_name))\n",
    "            else:\n",
    "                print(\n",
    "                    'warning: Image \"' + file_name +\n",
    "                    '\" with wrong size will be ignored!',\n",
    "                    file=sys.stderr)\n",
    "\n",
    "    return images, names\n",
    "\n",
    "\n",
    "# image file suffix\n",
    "suffix = 'pgm'\n",
    "\n",
    "# image size\n",
    "img_shape = (192, 168)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "train_imgs, train_names = read_images_from_directory('images/trainimg',\n",
    "                                                     'pgm', img_shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.gray()\n",
    "for i, n in enumerate(train_names):\n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(train_imgs[i])\n",
    "    plt.title(n[5:7])\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex-eigenface-pca-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Use PCA to compute the eigenfaces (i.e. the eigenvectors of the face images). You may use your PCA function from Exercise 1c or some build in function. Explain what kind of input PCA expects, and how that fits to our images (you may have to `reshape` the images!). Finally, display the eigenfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a8ca9a7fbbdedb2f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Transform images into one-dimensional vectors.\n",
    "# This will create a two dimension matrix of shape (n,k)\n",
    "# with n being the number of images and k the number of\n",
    "# pixels per image.\n",
    "face_vecs = train_imgs.reshape((-1, np.prod(img_shape)))\n",
    "\n",
    "\n",
    "# Compute the mean face.\n",
    "mean_face = face_vecs.mean(axis=0)\n",
    "\n",
    "# now we can project our images onto these eigenvectors,\n",
    "# obtaining n eigenfaces (each of dimensionality k):\n",
    "centered_faces = face_vecs - mean_face\n",
    "\n",
    "# As in our case k is much greater than n, we swap the dimensions when performing PCA:\n",
    "# Instead of computing the gigantic (k*k, k=32256) covariance matrix\n",
    "#   Cov = 1/(N-1) X^T * X\n",
    "# we compute the much smaller matrix (n*n, n=20)\n",
    "#   M = 1/(N-1) X * X^T\n",
    "matrix = centered_faces @ centered_faces.T / (len(centered_faces)-1)\n",
    "    \n",
    "# Computing eigenvalues and eigenvectors of covariance matrix.\n",
    "# Attention: not always sorted.\n",
    "eigenvals, eigenvecs = np.linalg.eigh(matrix)\n",
    "\n",
    "# Sort in order of descending magnitude\n",
    "idx = np.argsort(eigenvals)[::-1]\n",
    "eigenvecs, eigenvals = eigenvecs[:,idx], eigenvals[idx]\n",
    "\n",
    "# Now we can obtain the eigenfaces by projecting back into the original space.\n",
    "eigenfaces = eigenvecs.T @ centered_faces\n",
    "\n",
    "# Normalize the eigenfaces\n",
    "eigenfaces = eigenfaces/np.linalg.norm(eigenfaces, axis=1)[:,np.newaxis]\n",
    "\n",
    "assert len(eigenfaces) == len(face_vecs)\n",
    "\n",
    "# Plot eigenvalues and eigenvectors\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.gray();\n",
    "plt.subplot(1,3,1); plt.title(\"The mean face\")\n",
    "plt.imshow(mean_face.reshape(img_shape))\n",
    "plt.subplot(1,3,2); plt.title(\"Spectrum of eigenvalues\")\n",
    "plt.bar(np.arange(len(eigenvals)), eigenvals)\n",
    "plt.subplot(1,3,3); plt.title(\"Covariance\"); plt.axis('off')\n",
    "plt.imshow(eigenfaces @ eigenfaces.T)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ... and display the resulting eigenfaces:\n",
    "plt.figure(figsize=(12, 16))\n",
    "plt.gray()\n",
    "for i, eigenface in enumerate(eigenfaces):\n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(eigenface.reshape(img_shape))\n",
    "    plt.title(f\"Eigenface {i} (var={100*eigenvals[i]/eigenvals.sum():.2f}%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c54ec5985375835f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Now project the training face images into the eigenspace to calculate their ”feature vectors”,\n",
    "i.e. a representation with significantly lower dimension. For the projection of the face images,\n",
    "they have to be centered first, i.e. the mean face vector has to be subtracted. Store the mean face in some vector (`mean_face`) and the representation achieved in some array (`face_db`). Finally restore the images from `face_db` and display them alongside the original image. Try out the effect of changing the number of eigenfaces to be used (`num_eigenfaces`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-43eaeder3c18070c8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# number of eigenfaces to be used\n",
    "num_eigenfaces = 19\n",
    "\n",
    "# Remark: a value of 20 (theoretical perfect reconstruction) may suffer from numerical\n",
    "# instability (the last eigenface may introduce noise).\n",
    "# However, a value of 19 suffices for almost perfect reconstruction ...\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# Reduce the number of eigenfaces to achieve more dimensionality reduction.\n",
    "eigenfaces_used = eigenfaces[:num_eigenfaces]\n",
    "\n",
    "# Project images into the eigenface space and store\n",
    "# them in a \"eigenface database\":\n",
    "face_db = (face_vecs - mean_face) @ eigenfaces_used.T\n",
    "\n",
    "# ... and display the original image and the stored image\n",
    "print(f\"Eigenfaces used: {len(eigenfaces_used)}/{len(eigenfaces)}\")\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.gray()\n",
    "for i, face in enumerate(face_db):\n",
    "    restored = (face[np.newaxis] @ eigenfaces_used) + mean_face\n",
    "    plt.subplot(5, 8, 2 * i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(train_imgs[i])\n",
    "    plt.title('original')\n",
    "    plt.subplot(5, 8, 2 * i + 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(restored.reshape(img_shape))\n",
    "    plt.title('restored')\n",
    "plt.show()\n",
    "\n",
    "assert np.allclose(face_vecs, face_db @ eigenfaces_used + mean_face, atol=1e-4)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex-eigenface-recognize",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** Implement the function `recognize_face` that recognizes a face from that database by calculating the euclidean distance of this face feature vector to all of the training feature vectors from the database. The feature vector with the smallest distance represents the winner category. Check your implementation by recognizing the images from the training set (they should be recognized without error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-55d01bed03c2d1ca2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def recognize_face(face, eigenfaces, mean_face, face_db):\n",
    "    \"\"\"\n",
    "    Recognize a face from a face database.\n",
    "    and return the index of the best matching database entry.\n",
    "\n",
    "    The FACE is first centered and projected into the eigeface\n",
    "    space provided by EIGENFACES. Then the best match is found\n",
    "    according to the euclidean distance in the eigenface space.\n",
    "    \n",
    "    Args:\n",
    "        face (ndarray): Face to be recognised.\n",
    "        eigenfaces (ndarray): Array of eigenfaces.\n",
    "        mean_face (ndarray): Average face.\n",
    "        face_db (ndarray): Database of faces projectected into Eigenface space.\n",
    "        \n",
    "    Returns:\n",
    "        index (uint): Position of the best matching face in face_db.\n",
    "    \"\"\"\n",
    "    index = -1\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    # center the face\n",
    "    centered = face - mean_face\n",
    "\n",
    "    # and project it into the eigenface space\n",
    "    projected = eigenfaces @ centered\n",
    "\n",
    "    # Now compute the similarity to all known faces\n",
    "    # (comparison is performed in the eigenface space)\n",
    "    distances = cdist(face_db, projected[None, :])\n",
    "    index = distances.argmin()\n",
    "\n",
    "    # END SOLUTION\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "# ... and now check your function on the training set ...\n",
    "# BEGIN SOLUTION\n",
    "def show_recognition_results(imgs, labels, train_imgs, train_labels,\n",
    "                             num_eigenfaces, eigenfaces, mean_face, face_db):\n",
    "    \"\"\"Iterate over all face images and compute the best matching face in face_db.\n",
    "    \n",
    "    Args:\n",
    "        imgs (list): List of test faces.\n",
    "        train_imgs (list): List of training faces.\n",
    "        train_labels (list): List of training labels.\n",
    "        num_eigenfaces (uint): Number of eigenfaces.\n",
    "        eigenfaces (list): List of the eigenfaces.\n",
    "        mean_face (ndarray): Average face.\n",
    "        face_db (ndarray): Database of faces projectected into Eigenface space.\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    img_shape = imgs[0].shape\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.suptitle(\n",
    "        'Face recognition based on {} principal components'.format(num_eigenfaces))\n",
    "    plt.gray()\n",
    "    for j, img in enumerate(imgs):\n",
    "\n",
    "        # find the best match in the eigenface database\n",
    "        winner = recognize_face(\n",
    "            img.reshape(np.prod(img_shape)), eigenfaces, mean_face, face_db)\n",
    "        name_label = labels[j][5:7]\n",
    "        name_winner = train_labels[winner][5:7]\n",
    "\n",
    "        plt.subplot(5, 8, 2 * j + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.title(labels[j][5:7])\n",
    "\n",
    "        plt.subplot(5, 8, 2 * j + 2)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(train_imgs[winner])\n",
    "        t = plt.title(('*' if name_label != name_winner else '') + name_winner)\n",
    "        plt.setp(t, color='r' if name_label != name_winner else 'g') \n",
    "    plt.show()\n",
    "    \n",
    "show_recognition_results(train_imgs, train_names,\n",
    "                         train_imgs, train_names,\n",
    "                         num_eigenfaces, eigenfaces_used, \n",
    "                         mean_face, face_db)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Now classify the images in directory `images/testimg/`. Try to reduce the number of principal components\n",
    "used. How many PCs are necessary to still achieve perfect classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-47ccaee3973f6ac4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_imgs, test_names = read_images_from_directory('images/testimg', suffix,\n",
    "                                                   img_shape)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "show_recognition_results(test_imgs, test_names,\n",
    "                         train_imgs, train_names,\n",
    "                         num_eigenfaces, eigenfaces_used, \n",
    "                         mean_face, face_db)\n",
    "#END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-968c945b0dc138ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3: Local features and interest points [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54385603796cbdc5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain in your own words: What are *local features*? How are they used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9ab13a0e8484d6b9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Local features are used in object recognition to make it more resiliant against object rotation, partial occlusion, illuminence differences, scaling etc. This is achieved by using not the whole object but the most interesting parts of it - local patches that describe the object and are most of the time available in other representations of that object (for example the wheels and lights of a car, but not it's color)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a58a036bbdcba63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "solution": "hidden"
   },
   "source": [
    "**b)** What are *interest points* and what are they used for? What properties are desirable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b964929c6f2d5419",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": "hidden"
   },
   "source": [
    "Interest points are points in an image and can be used for object recognition. \n",
    "\n",
    "They should be salient, i.e. “special” or “rare”, either within the image, or with respect to “common” images.\n",
    "\n",
    "They should be stable, i.e. should keep positions under disruptions in an image and should remain in the same position with respect to the physical world in a different image of the same scene (e.g., change of viewpoint or illumination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bffcd57e4ade7360x",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4: Computing interest points [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-moravec-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain in your own words the idea of the Moravec IP operator. What are its properties? Implement this IP operator and apply it to the image `lighthouse.png`. Try different window sizes and threshold values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e5a892a0e5b57489",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The Moravec IP operator measures the saliency or \"uniqueness\" of a window arround a pixel. In the simplest case the window is shifted by one pixel and compared to itself. This is done in both horizontal and vertical directions. The detector response is the miminum over the four directions. A corner is detected where the response exceeds a threshold.\n",
    "The Moravec operator is anisotropic, meaning direction dependent, and uses a \"hard\" window like a box filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-moravec-a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imageio.imread('images/lighthouse.png', pilmode='F')\n",
    "\n",
    "window_size = 3\n",
    "threshold = .2\n",
    "\n",
    "def moravec(img, window_size):\n",
    "    \"\"\"Moravec corner detector.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    img: np.ndarray\n",
    "        The input image\n",
    "    window_size: int\n",
    "        The size of the window to consider\n",
    "\n",
    "    Results\n",
    "    -------\n",
    "    response: np.ndarray\n",
    "        Response (of the same size as img), indicating interest points.\n",
    "    \"\"\"\n",
    "    response = np.zeros_like(img)\n",
    "    # BEGIN SOLUTION\n",
    "    wsh = window_size//2\n",
    "    for i in np.arange(window_size, img.shape[0] - window_size):\n",
    "        for j in np.arange(wsh, img.shape[1] - window_size):\n",
    "            patch = img[i-wsh:i+wsh+1, j-wsh:j+wsh+1]\n",
    "        \n",
    "            right = np.sum((patch - img[ i - wsh : i + wsh + 1, j : j + window_size])**2)\n",
    "            up = np.sum((patch - img[ i - window_size + 1: i + 1, j - wsh : j + wsh + 1])**2)\n",
    "            up_right = np.sum((patch - img[ i - window_size + 1: i + 1, j : j + window_size])**2)\n",
    "            down_right = np.sum((patch - img[ i : i + window_size, j : j + window_size])**2)\n",
    "        \n",
    "            response[i,j] = min(right, up, up_right, down_right)\n",
    "    return response\n",
    "\n",
    "# alternative implementation:\n",
    "def moravec2(img, window_size):\n",
    "    diff_right = (img[1:-1,1:] - img[1:-1,:-1])**2\n",
    "    diff_up = (img[:-2,1:] - img[1:-1,1:])**2\n",
    "    diff_up_right = (img[:-2,1:] - img[1:-1,:-1])**2\n",
    "    diff_down_right = (img[2:,1:] - img[1:-1,:-1])**2\n",
    "\n",
    "    kernel = np.ones((window_size, window_size))\n",
    "    E_right = nd.convolve(diff_right, kernel)\n",
    "    E_up = nd.convolve(diff_up, kernel)\n",
    "    E_up_right = nd.convolve(diff_up_right, kernel)\n",
    "    E_down_right = nd.convolve(diff_down_right, kernel)\n",
    "    \n",
    "    response = np.stack((E_right, E_up, E_up_right, E_down_right)).min(axis=0)\n",
    "    response /= response.max()\n",
    "    # END SOLUTION\n",
    "    return response\n",
    "\n",
    "#response = moravec(img, window_size)\n",
    "response = moravec2(img, window_size)\n",
    "\n",
    "thresholded = np.zeros_like(response)\n",
    "thresholded[response > threshold] = 1\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1); plt.imshow(img, cmap='gray'); plt.title('Original')\n",
    "plt.subplot(2,2,2); plt.imshow(response, cmap='viridis'); plt.title('Moravec \"heatmap\"')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3); plt.imshow(thresholded, cmap='gray'); plt.title(f'Thresholded (>{threshold})')\n",
    "plt.subplot(2,2,4); plt.imshow(img[1:-1,:-1], cmap='gray'); plt.title('Corners')\n",
    "mask = np.zeros(thresholded.shape + (4,), dtype=np.int)\n",
    "mask[:,:,0] = 255\n",
    "mask[:,:,3] = thresholded*255\n",
    "plt.imshow(mask, interpolation='none')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-harris-q",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** How does the Harris corner detector work and in what sense does it improve the Moravec IP operator. Implement the Harris corner detector and apply it to `lighthouse.png`. Again, try different \"window sizes\" (values for $\\sigma$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d51a9747dd39f80b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Harris corner detector uses a Gaussian as isotropic windowing function addressing both shortcommings, the \"hard\" window and the anisotropy of the Moravec detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-harris-a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "k = .04\n",
    "window_size = 3\n",
    "\n",
    "img = imageio.imread('images/lighthouse.png', pilmode='F')/255.\n",
    "\n",
    "def harris(img, window_size=3, k=0.04):\n",
    "    \"\"\"Harris corner detector.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    img: np.ndarray\n",
    "        The input image\n",
    "    window_size: int\n",
    "        The size of the window to consider\n",
    "    k: float\n",
    "        The parameter k\n",
    "        \n",
    "    Results\n",
    "    -------\n",
    "    response: np.ndarray\n",
    "        Response (of the same size as img), indicating interest points.\n",
    "    \"\"\"\n",
    "    response = np.zeros_like(img)\n",
    "    # BEGIN SOLUTION\n",
    "    \n",
    "    # probably there is a more efficient implementation ...\n",
    "    \n",
    "    wsh = window_size//2\n",
    "\n",
    "    dx = nd.sobel(img, 1) \n",
    "    dy = nd.sobel(img, 0)\n",
    "    dx2 = np.multiply(dx, dx)\n",
    "    dy2 = np.multiply(dy, dy)\n",
    "    dxy = np.multiply(dx, dy)\n",
    "\n",
    "    kernel = np.zeros((window_size, window_size))\n",
    "    kernel[wsh, wsh] = 1\n",
    "    kernel = nd.filters.gaussian_filter(kernel, wsh/1, truncate = 1)\n",
    "\n",
    "    for i in np.arange(wsh, img.shape[0] - wsh):\n",
    "        for j in np.arange(wsh, img.shape[1] - wsh):\n",
    "        \n",
    "            a_ = dx[i - wsh : i + wsh + 1, j - wsh : j + wsh + 1]         \n",
    "            b_ = dy[i - wsh : i + wsh + 1, j - wsh : j + wsh + 1]         \n",
    "            a = np.sum(np.multiply(kernel, dx2[i - wsh : i + wsh + 1, j - wsh : j + wsh + 1]))       \n",
    "            b = np.sum(np.multiply(kernel, dy2[i - wsh : i + wsh + 1, j - wsh : j + wsh + 1]))\n",
    "            c = np.sum(np.multiply(kernel, dxy[i - wsh : i + wsh + 1, j - wsh : j + wsh + 1]))         \n",
    "\n",
    "            # Noble's corner measure\n",
    "            #response[i,j] = 2 * ((a * b - c ** 2) / ((a + b) ** 2 + 1e-5))\n",
    "            response[i,j] = a * b - c ** 2 - k * (a + b) **2\n",
    "    return response\n",
    "\n",
    "def harris2(img, window_size=3, k=0.04):\n",
    "\n",
    "    # compute the derivatives\n",
    "    dx, dy = nd.sobel(img, 1), nd.sobel(img, 0)\n",
    "    dx2, dy2, dxy = dx**2, dy**2, dx * dy\n",
    "\n",
    "    # apply apply the Gaussian window\n",
    "    a = nd.filters.gaussian_filter(dx2, (window_size-1)/6, truncate = 3)\n",
    "    b = nd.filters.gaussian_filter(dy2, (window_size-1)/6, truncate = 3)\n",
    "    c = nd.filters.gaussian_filter(dxy, (window_size-1)/6, truncate = 3)\n",
    "    \n",
    "    # and compute the response signal\n",
    "    response = a * b - c ** 2 - k * (a + b) **2\n",
    "    # END SOLUTION\n",
    "    return response\n",
    "\n",
    "response = harris(img, window_size, k)\n",
    "corners = response.copy()        \n",
    "corners[response<0] = 0\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1); plt.imshow(img, cmap='gray'); plt.title(\"Original\")\n",
    "plt.subplot(2,2,2); plt.imshow(response, cmap='viridis'); plt.title('Harris \"heatmap\"')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3); plt.imshow((corners**.25), cmap='gray'); plt.title(f\"Thresholded (<0)\")\n",
    "plt.subplot(2,2,4); plt.imshow(img, cmap='gray'); plt.title('Corners')\n",
    "mask = np.zeros(corners.shape + (4,), dtype=np.int)\n",
    "mask[:,:,0] = 255\n",
    "mask[:,:,3] = (response>0)*255\n",
    "plt.imshow(mask, interpolation='none')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
